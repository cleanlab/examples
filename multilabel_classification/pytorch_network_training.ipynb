{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a neural network for multi-label classification on the CelebA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a Pytorch neural network for image tagging and use the model to produce out-of-sample predicted class probabilities for each image in the dataset. These are required inputs to find label errors in multi-label classification datasets with cleanlab. Here we consider a subset of the [CelebA](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset) dataset, where each image may be tagged with one or more of the following tags: `['Wearing_Hat', 'Wearing_Necklace', 'Wearing_Necktie', 'Eyeglasses', 'No_Beard', 'Smiling']`, depending on which ones apply to the person depicted.\n",
    "\n",
    "This notebook only shows how to train the network andÂ use it to produce `pred_probs`, using them to find label issues is demonstrated in cleanlab's Tutorial on [Multi-Label Classification](https://docs.cleanlab.ai/). Here we fit a state-of-the-art neural network initialized from a pretrained [TIMM](https://timm.fast.ai/) network backbone. You can use this same code to obtain a multi-label classifier (i.e. image tagging model) for *any* image dataset.\n",
    "\n",
    "We first need to download the dataset (if you don't have `wget` installed you can fetch it manually from the link below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc -O 'archive.zip' 'https://storage.googleapis.com/kaggle-data-sets/29561/37705/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221102%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221102T043448Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4a8303ca846eaae80b62ff3705ad6b86de91724f8d76b4373083c4c33225314b6c43af9bab79e32100af51aa02e230a1eaa81ae33aea94680fbb118fb74dd6bf4d2a9426809a43ce699da806f156781c98f5076845d8936c304657265ecaa323ba0a369aa7d436916a6a87ba8a5873865da1b30052c9f128f2005fa12e1526850a79fe96e74aa698bc4ce59b3822d159b22ece231b7246d7800b685c5e9974e7837dfb4d2d7c18147749443bdbe9ae44f5db3e045f25774df6d464c7f0762279fea7b201ce76ceb15d1301f4354112db105c108dd5564f3a165f9f2af1fb581f5fa6d5b471a194007290b03637a38105c09a3c6f2aebb26e3df2fccf49d349a6'\n",
    "!unzip -qq archive.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import required dependencies (make sure you have installed these packages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "from timm.optim import create_optimizer\n",
    "from timm.models import create_model\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.loader import create_loader\n",
    "from timm.utils import CheckpointSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the dataset, and preprocess it to only keep the classes of interest (i.e. *image tags*) listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"list_attr_celeba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map -1 entries -> 0\n",
    "dat[dat.columns[1:]] = ((dat[dat.columns[1:]]+1)/2).astype(np.int32)\n",
    "\n",
    "selected = ['image_id',\n",
    "'Eyeglasses',\n",
    " 'Wearing_Earrings',\n",
    " 'Wearing_Hat',\n",
    " 'Wearing_Necklace',\n",
    " 'Wearing_Necktie',\n",
    " 'No_Beard',\n",
    " 'Smiling']\n",
    "\n",
    "def is_label(row):\n",
    "    for s in selected[1:]:\n",
    "        if row[s]!=0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_loc(i):\n",
    "    return os.path.join(os.getcwd(),'img_align_celeba/img_align_celeba/')+i\n",
    "\n",
    "dat_label = dat.apply(is_label,axis=1)\n",
    "dat_selected = dat[dat_label][selected]\n",
    "dat_selected['image_path'] = dat_selected['image_id'].map(lambda x:get_loc(x))\n",
    "selected[0] = 'image_path'\n",
    "\n",
    "df = dat_selected[selected]\n",
    "set_lab = {}\n",
    "for i,row in df.iterrows():\n",
    "    q = str(row.tolist()[1:])\n",
    "    if q not in set_lab:\n",
    "        set_lab[(str(q))]=len(set_lab)\n",
    "\n",
    "# Here we drop a couple rare class-combinations just to simplify stratified data splitting\n",
    "def get_lab(row):\n",
    "    q = str(row.tolist()[1:])\n",
    "    return set_lab[q]\n",
    "\n",
    "df['unique_label'] = df.apply(get_lab,axis=1)\n",
    "cnt = Counter(df['unique_label'])\n",
    "\n",
    "def drop(val):\n",
    "    if cnt[val]>10:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "is_drop = df['unique_label'].apply(lambda x:drop(x))\n",
    "df = df[is_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting DataFrame contains the ID of each image and the classes (i.e. *tags*) that apply to this image.\n",
    "\n",
    "We define a general class of Pytorch neural networks for multi-label image classification. You can use this class for training models on *any* image dataset, and this class can utilize *any* pretrained [TIMM](https://timm.fast.ai/) network backbone. The `MultiLabelModel` below adds an appropriate output layer on top of the network backbone and then fine-tunes the entire network jointly on your multi-label classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelModel(nn.Module):\n",
    "    \"\"\" \n",
    "    Pytorch network for multi-label classification that can utilize any TIMM network backbone.\n",
    "    Some of this code is inspired by: https://github.com/yang-ruixin/PyTorch-Image-Models-Multi-Label-Classification\n",
    "    Note this network uses Sigmoid output activations because the predicted probabilities do not need to sum to 1\n",
    "    for multi-label classification, in which each image may belong to multiple classes rather than only one.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, n_classes, class_weights=None, verbose = False):\n",
    "        super().__init__()\n",
    "        self.base_model = model  # network backbone can be any TIMM model\n",
    "        self.num_classes = n_classes\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_loss(self, loss_fn, output, target):\n",
    "\n",
    "        return loss_fn(output, target)\n",
    "\n",
    "    def validate(self, loader):\n",
    "        self.eval();\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            m = nn.Sigmoid()\n",
    "            labels = []\n",
    "            preds = []\n",
    "            for batch_idx, (input, target) in enumerate(loader):\n",
    "                input = input.cuda()\n",
    "                labels.append(target.detach().cpu())\n",
    "                target = target.float().cuda()\n",
    "                output = m(self(input))\n",
    "                loss = self.get_loss(loss_fn, output, target)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                pred_model = (output > 0.5).detach().cpu()\n",
    "                preds.append(pred_model)\n",
    "\n",
    "            num_of_batches_per_epoch = len(loader)\n",
    "            avg_loss = total_loss / num_of_batches_per_epoch\n",
    "            print(\"VALIDATION DATA STATS\")\n",
    "\n",
    "            print(\"AVERAGE LOSS:\", avg_loss)\n",
    "            preds = torch.cat(preds).int()\n",
    "            labels = torch.cat(labels).int()\n",
    "            acc_score = accuracy_score(labels, preds)\n",
    "            print(\"MULTILABEL accuracy score:\", acc_score)\n",
    "            per_class = []\n",
    "            for i in range(len(preds.T)):\n",
    "                per_class.append(accuracy_score(labels.T[i], preds.T[i]))\n",
    "            print(dataset_train.label_names)\n",
    "            print(per_class)\n",
    "            print('\\n\\n')\n",
    "        return avg_loss\n",
    "\n",
    "    def predict_proba(self, loader):\n",
    "        self.eval();\n",
    "        with torch.no_grad():\n",
    "            m = nn.Sigmoid()\n",
    "            preds = []\n",
    "            for batch_idx, (input, target) in enumerate(loader):\n",
    "                input = input.cuda()\n",
    "                output = m(self(input))\n",
    "                pred_model = output.detach().cpu()\n",
    "                preds.append(pred_model)\n",
    "            preds = torch.cat(preds)\n",
    "        return preds\n",
    "\n",
    "    def train_one_epoch(\n",
    "        self,\n",
    "        loader,\n",
    "        optimizer,\n",
    "        loss_fn,\n",
    "    ):\n",
    "        sta = time.time()\n",
    "        second_order = hasattr(optimizer, \"is_second_order\") and optimizer.is_second_order\n",
    "        self.train()\n",
    "        total_loss = 0\n",
    "        m = nn.Sigmoid()\n",
    "        labels = []\n",
    "        preds = []\n",
    "        ct = 0\n",
    "        for batch_idx, (input, target) in enumerate(loader):\n",
    "            input = input.cuda()\n",
    "            ct += 1\n",
    "            labels.append(target.detach().cpu())\n",
    "            target = target.float().cuda()\n",
    "            output = m(self(input))\n",
    "            loss = self.get_loss(loss_fn, output, target)\n",
    "            total_loss += loss.item()\n",
    "            pred_model = (output > 0.5).detach().cpu()\n",
    "            preds.append(pred_model)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(create_graph=second_order)\n",
    "            optimizer.step()\n",
    "            if ct % 80 == 0 and self.verbose:\n",
    "                print(\"LOSS:\", loss.item())\n",
    "        num_of_batches_per_epoch = len(loader)\n",
    "        avg_loss = total_loss / num_of_batches_per_epoch\n",
    "        print(\"TRAINING DATA STATS\")\n",
    "        print(\"AVERAGE LOSS:\", avg_loss)\n",
    "        preds = torch.cat(preds).int()\n",
    "        labels = torch.cat(labels).int()\n",
    "        acc_score = accuracy_score(labels, preds)\n",
    "        print(\"MULTILABEL accuracy score:\", acc_score)\n",
    "        per_class = []\n",
    "        for i in range(len(preds.T)):\n",
    "            per_class.append(accuracy_score(labels.T[i], preds.T[i]))\n",
    "        print(dataset_train.label_names)\n",
    "        print(per_class)\n",
    "        print('\\n\\n')\n",
    "        sto = time.time()\n",
    "        print(\"training time\", sto - sta)\n",
    "        return avg_loss\n",
    "    \n",
    "\n",
    "    def fit(self, loader_train, load_val, num_epochs=10):\n",
    "        if os.path.exists(\"weights_model\"):\n",
    "            print(\"removing weights directory\")\n",
    "            os.system('rm -rf weights_model')\n",
    "        os.mkdir(\"weights_model\")\n",
    "        args = SimpleNamespace()\n",
    "        args.weight_decay = 0\n",
    "        args.lr = 1e-4\n",
    "        args.opt = 'adam'\n",
    "        args.momentum = 0.9\n",
    "        args.sched = \"step\"\n",
    "\n",
    "        optimizer = create_optimizer(args, self)\n",
    "        saver = CheckpointSaver(\n",
    "            model=self,\n",
    "            optimizer=optimizer,\n",
    "            checkpoint_dir=\"weights_model\"\n",
    "        )\n",
    "        errs = []\n",
    "        num_of_data_train = len(loader_train.dataset.data)\n",
    "        for epoch in range(0, num_epochs):\n",
    "            loss_train = self.train_one_epoch(\n",
    "                loader_train,\n",
    "                optimizer,\n",
    "                loss_fn,\n",
    "            )\n",
    "            loss_val = self.validate(loader_val)\n",
    "            errs.append([loss_train, loss_val])\n",
    "            saver.save_checkpoint(epoch, metric=loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a wrapper class for training our `MultiLabel` model on multi-label classification image datasets. You can easily apply this to your own datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMultiLabel(data.Dataset):\n",
    "    def __init__(\n",
    "            self,\n",
    "            annotation_path=None,\n",
    "            df = None,\n",
    "            transform=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.label_names = []\n",
    "        if annotation_path is None:\n",
    "            assert df is not None\n",
    "        else:\n",
    "            df = pd.read_csv(annotation_path)\n",
    "        \n",
    "        cols = df.columns\n",
    "        self.label_names = list(cols[1:-1])\n",
    "        for i,row in df.iterrows():\n",
    "            lb = []\n",
    "            for j in cols:\n",
    "                if j=='unique_label':\n",
    "                    continue\n",
    "                if j=='image_path':\n",
    "                    self.data.append(row[j])\n",
    "                else:\n",
    "                    lb.append(float(row[j]))\n",
    "            self.labels.append(lb)\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        return img, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "  Re-initializes model weights, eg. between cross-validation folds. \n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        layer.reset_parameters()\n",
    "\n",
    "def create_df(pred_probs, dataset):\n",
    "    \"\"\"\n",
    "    Returns a dataframe with image_loc and predicted probabilities for each image.\n",
    "    \"\"\"\n",
    "    ls = dataset_val.label_names\n",
    "    cl = defaultdict(list)\n",
    "    cl['image_loc'] = dataset.data\n",
    "    for i in range(0,len(ls)):\n",
    "        cl[ls[i]] = pred_val.T[i].tolist()\n",
    "    return pd.DataFrame.from_dict(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `DatasetMultiLabel` and `MultiLabelModel` for the Celeb-A dataset. Here we use the [efficientnet_b0](https://rwightman.github.io/pytorch-image-models/models/tf-efficientnet/) backbone for our neural network, but you can easily use any other TIMM backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetMultiLabel(df = df)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "model = create_model(\n",
    "    'efficientnet_b0',  # you can replace this with any TIMM backbone\n",
    "    num_classes=len(dataset.labels[0]),\n",
    ")\n",
    "data_config = resolve_data_config(\n",
    "       args = {}, model=model\n",
    "    )\n",
    "\n",
    "model = MultiLabelModel(\n",
    "        model,\n",
    "        n_classes=len(dataset.labels[0]),\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train this network using K-fold cross validation. This allows us to obtain **out-of-sample** predictions for each image in the dataset (i.e. predictions from a copy of the model which never saw this image during training). Out-of-sample predictions are less prone to overfitting, and thus better suited for finding label issues. From each fold of cross-validation, we store the predicted class probabilities for the images that were out-of-sample in a DataFrame `df_pred`. These predictions are subsequently used for finding label issues in cleanlab's Tutorial on [Multi-Label Classification](https://docs.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 4  # number of cross-validation splits (higher values will take longer but give better results)\n",
    "skf = StratifiedKFold(n_splits=num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct = 1\n",
    "for train_index, test_index in skf.split(df,df['unique_label']):\n",
    "    if ct!=1:\n",
    "        model.apply(reset_weights);\n",
    "    dataset_train = DatasetMultiLabel(df = df.iloc[train_index])\n",
    "    dataset_val = DatasetMultiLabel(df = df.iloc[test_index])\n",
    "    loader_train = create_loader(\n",
    "        dataset_train,\n",
    "        input_size=data_config[\"input_size\"],\n",
    "        batch_size=64,\n",
    "        is_training=True,\n",
    "        mean=data_config[\"mean\"],\n",
    "        std=data_config[\"std\"],\n",
    "       interpolation=data_config[\"interpolation\"],\n",
    "    )\n",
    "    loader_val = create_loader(\n",
    "        dataset_val,\n",
    "        input_size=data_config[\"input_size\"],\n",
    "        batch_size=64,\n",
    "        is_training=False,\n",
    "        mean=data_config[\"mean\"],\n",
    "        std=data_config[\"std\"],\n",
    "        interpolation=data_config[\"interpolation\"],\n",
    "\n",
    "    )\n",
    "    model.fit(loader_train,loader_val,num_epochs=40)\n",
    "    checkpoint = torch.load(\"weights_model/model_best.pth.tar\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    pred_val = model.predict_proba(loader_val)\n",
    "    df_pred = create_df(pred_val,dataset_val)\n",
    "    df_pred.to_csv(str(ct)+\"_fold.csv\",index=False)\n",
    "    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = []\n",
    "for i in range(1,num_splits+1):\n",
    "    dfl.append(pd.read_csv(str(i)+\"_fold.csv\"))\n",
    "\n",
    "cols = dfl[0].columns[1:]\n",
    "df_pred = pd.concat(dfl,axis=0)\n",
    "df_pred['image_loc'] = df_pred['image_loc'].map(lambda x:x.split('/')[-1])\n",
    "df_pred.set_index('image_loc').to_csv(\"pred_probs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
