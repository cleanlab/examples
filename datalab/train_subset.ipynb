{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier Training on Caltech-256 Subset\n",
    "\n",
    "In this notebook, we will train a Swin Transformer model for image classifier on a subset of the Caltech-256 dataset using the Timm library and Pytorch. The main steps include dataset sampling and precrocessing, model training with k-fold cross-validation, and feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision.datasets import Caltech256, ImageFolder\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "Before we start training, we need to prepare the dataset. \n",
    "\n",
    "This includes loading the dataset, selecting a subset of categories, and applying necessary transformations, which we define below.\n",
    "\n",
    "Note that we're not interested in any data augmentation techniques for this task, so we only apply a simple normalization transform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rgb(img):\n",
    "    if img.mode == 'L':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "DATA_DIR = './data' # Save notebook artifacts in this directory\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(  # ImageNet stats for normalization (mean and std) of RGB channels\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Subset of Categories\n",
    "\n",
    "We will select a specific subset of categories from the Caltech-256 dataset to create a smaller dataset for training via cross-validation.\n",
    "\n",
    "The categories are restricted to aquatic/semi-aquatic animals (amphibians and birds).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following categories\n",
    "categories_subset = [\"080.frog\", \"256.toad\", \"158.penguin\", \"114.ibis-101\", \"207.swan\"]\n",
    "categories_subset.sort()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Dataset Class\n",
    "\n",
    "We will create a custom dataset class named `Caltech256Subset` that inherits from Torchvision's `Caltech256` dataset class. This custom class will handle filtering and moving the data based on the selected categories and clutter ratio to a new directory on the local filesystem.\n",
    "\n",
    "This class is far from perfect, but it's good enough for our purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Caltech256Subset(Caltech256):\n",
    "    def __init__(self, root, categories_subset, transform=None, target_transform=None, download=False, clutter_ratio=0.1, seed=42):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform, download=download)\n",
    "        \n",
    "        self.original_categories = self.categories\n",
    "        self.original_idx_to_class = {i: class_name for i, class_name in enumerate(self.original_categories)}\n",
    "        self.original_class_to_idx = {class_name: i for i, class_name in enumerate(self.original_categories)}\n",
    "        \n",
    "        self.categories_subset = categories_subset\n",
    "        self.idx_to_class = {i: class_name for i, class_name in enumerate(categories_subset)}\n",
    "        self.class_to_idx = {class_name: i for i, class_name in enumerate(categories_subset)}\n",
    "        \n",
    "        self.subset_data_dir = os.path.join(root, 'caltech256-subset')\n",
    "        os.makedirs(self.subset_data_dir, exist_ok=True)\n",
    "        \n",
    "        self.clutter_indices = []\n",
    "        self.clutter_ratio = clutter_ratio\n",
    "        \n",
    "        random.seed(seed)\n",
    "        self._filter_and_move_data()\n",
    "\n",
    "\n",
    "    def _filter_and_move_data(self):\n",
    "        subset_indices = []\n",
    "        new_labels = []\n",
    "\n",
    "        seen_images = set()\n",
    "        existing_subset_images = set()\n",
    "        for idx, label in enumerate(self.y):\n",
    "            class_name = self.categories[label]\n",
    "\n",
    "            if class_name not in self.categories_subset + [\"257.clutter\"]:\n",
    "                continue\n",
    "\n",
    "            if class_name == \"257.clutter\" and random.random() > self.clutter_ratio:\n",
    "                continue\n",
    "\n",
    "            if class_name in self.categories_subset:\n",
    "                new_label = self.class_to_idx[class_name]\n",
    "            else:\n",
    "                new_label = random.choice(list(self.class_to_idx.values()))\n",
    "                self.clutter_indices.append(idx)\n",
    "\n",
    "            subset_indices.append(idx)\n",
    "            new_labels.append(new_label)\n",
    "            \n",
    "\n",
    "            src_path = os.path.join(self.root, \"256_ObjectCategories\", self.categories[label], f\"{label + 1:03d}_{self.index[idx]:04d}.jpg\")\n",
    "            \n",
    "            assert src_path not in seen_images\n",
    "            seen_images.add(src_path)\n",
    "\n",
    "            dest_path = os.path.join(self.subset_data_dir, self.categories_subset[new_label], f\"{label + 1:03d}_{self.index[idx]:04d}.jpg\")\n",
    "            \n",
    "            dest_path_file = os.path.basename(dest_path)\n",
    "            assert dest_path_file not in existing_subset_images\n",
    "            existing_subset_images.add(dest_path_file)\n",
    "            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "            shutil.copyfile(src_path, dest_path)\n",
    "\n",
    "        self.y_original = self.y\n",
    "        self.y = new_labels\n",
    "\n",
    "        self.index_original = self.index\n",
    "        self.index_subset = subset_indices\n",
    "        self.index = [self.index[idx] for idx in subset_indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        original_index = self.index_subset[index]\n",
    "        y = self.y[index]\n",
    "        original_y = self.y_original[original_index]\n",
    "        img = Image.open(\n",
    "            os.path.join(\n",
    "                self.subset_data_dir,\n",
    "                self.categories_subset[y],\n",
    "                f\"{original_y + 1:03d}_{self.index_original[original_index]:04d}.jpg\"\n",
    "            )\n",
    "        ).convert('RGB')\n",
    "\n",
    "        target = self.y[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Data Directory and Removing Existing Directories\n",
    "\n",
    "We will now set up the data directory, removing any existing directories before creating new subset of the Caltech-256 dataset.\n",
    "\n",
    "Then, we will load the dataset from the local filesystem with Torchvision's `ImageFolder` class, including the transformations we defined above for training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the following lines to resample the subset of Caltech256 dataset, removing the existing subset.\n",
    "# # Otherwise, go to the next cell to load the existing subset.\n",
    "\n",
    "\n",
    "# if not os.path.exists(DATA_DIR):\n",
    "#     os.makedirs(DATA_DIR)\n",
    "\n",
    "# # Remove all directories in DATA_DIR/caltech256-subset if they exist\n",
    "# for dir_name in os.listdir(DATA_DIR):\n",
    "#     if dir_name.startswith(\"caltech256-subset\"):\n",
    "#         image_folder_root = os.path.join(DATA_DIR, dir_name)\n",
    "#         for subdir_name in os.listdir(image_folder_root):\n",
    "#             subdir_path = os.path.join(image_folder_root, subdir_name)\n",
    "#             shutil.rmtree(subdir_path)\n",
    "#             print(\"Removing\", subdir_path)\n",
    "\n",
    "# Create a subset of Caltech256 dataset, saving it in DATA_DIR/caltech256-subset     \n",
    "# Caltech256Subset(\n",
    "#     DATA_DIR,\n",
    "#     categories_subset=categories_subset,\n",
    "#     download=True,\n",
    "#     clutter_ratio=0.025  # Adjust this value to control the proportion of clutter examples included\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the subset of Caltech256 dataset from local disk\n",
    "dataset_subset = ImageFolder(\n",
    "    os.path.join(DATA_DIR, \"caltech256-subset\"),\n",
    "    transform=transform\n",
    ")\n",
    "n_classes_subset = len(dataset_subset.classes)\n",
    "labels_subset = np.array(dataset_subset.targets)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "With the dataset ready, we now define the hyperparameters for training and perform k-fold cross-validation to train Swin Transformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "batch_size = 32 # Resnet50: 64, Swin-Transformer-patch-4-window-7-224: 32\n",
    "learning_rate = 0.00001 # Resnet50: 0.001, Swin-Transformer-patch-4-window-7-224: 0.0001\n",
    "num_epochs = 10\n",
    "num_folds = 5  # Use 3 for faster training\n",
    "patience = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = \"swin_base_patch4_window7_224\"\n",
    "model_prefix = \"caltech256_subset_\" + model_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation and Training\n",
    "\n",
    "In this notebook, we use k-fold cross-validation to train the model and extract out-of-sample predicted probabilities for all data points.\n",
    "\n",
    "During the training process, we set aside a validation split on a per-fold basis to allow early stopping for each fold. This approach helps us prevent overfitting and obtain a better estimate of the model's performance.\n",
    "\n",
    "While we're not specifically interested in the model artifacts themselves, we aim to get a general idea of whether the chosen model architecture is accurate enough for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(dataset_subset, labels_subset)):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "    print('-' * 10)\n",
    "\n",
    "\n",
    "    # Define data loaders for current fold\n",
    "    train_subset = torch.utils.data.Subset(dataset_subset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset_subset, test_idx)\n",
    "    # Print train and validation set sizes\n",
    "    print(f'Train set size: {len(train_idx)}')\n",
    "    print(f'Test set size: {len(test_idx)}')\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model for current fold\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=n_classes_subset)\n",
    "    model = model.to(device)\n",
    "    num_features = model.num_features\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    best_epoch = 0\n",
    "    # Train model for current fold\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        model.train()\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Train loss: {loss:.4f}')\n",
    "\n",
    "        # Evaluate model on training set for current fold\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            eval_loader = train_loader\n",
    "            for inputs, targets in tqdm(val_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "            val_accuracy = 100 * correct / total\n",
    "            print(f'Validation accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        # Save model checkpoint if it is the best so far\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            print('Saving model...')\n",
    "            path = f'{model_prefix}_fold_{fold + 1}.pt'\n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch - best_epoch > patience:\n",
    "            print(f'Early stopping at epoch {epoch + 1}')\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "After training the model, we will compute predicted probabilities for the entire dataset using the trained models from each fold.\n",
    "\n",
    "To keep things simple, we'll use the model trained on the first fold as a feature extractor for every image in the dataset.\n",
    "\n",
    "These artifacts will be used by `Datalab` to inspect the dataset for potential issues.\n",
    "\n",
    "\n",
    "We will also compute pretrained features without fine-tuning the model, which can be used to compare the performance of the fine-tuned model on feature-based issue checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name, pretrained=True, num_classes=n_classes_subset)\n",
    "path = f'{model_prefix}_fold_1.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "num_features = model.num_features\n",
    "\n",
    "features = np.zeros((len(dataset_subset),num_features))\n",
    "pred_probs = np.zeros((len(dataset_subset), n_classes_subset))\n",
    "\n",
    "for fold, (_, test_idx) in enumerate(kf.split(dataset_subset, labels_subset)):\n",
    "    # Save out-of-sample predictions and features for current fold\n",
    "    # This is the validation set\n",
    "    # Define data loaders for current fold\n",
    "    test_subset = torch.utils.data.Subset(dataset_subset, test_idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=n_classes_subset)\n",
    "    path = f'{model_prefix}_fold_{fold + 1}.pt'\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_probs_fold = []\n",
    "        for inputs, _ in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Predicted probabilities\n",
    "            outputs = nn.functional.softmax(outputs, dim=1)\n",
    "            pred_probs_fold.append(outputs.cpu().numpy())\n",
    "        pred_probs[test_idx] = np.concatenate(pred_probs_fold, axis=0)\n",
    "        \n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=n_classes_subset)\n",
    "    path = f'{model_prefix}_fold_1.pt'\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        features_fold = []\n",
    "        model.reset_classifier(0)\n",
    "        for inputs, _ in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            features_fold.append(model(inputs).cpu().numpy())\n",
    "        features[test_idx] = np.concatenate(features_fold, axis=0)\n",
    "\n",
    "features_path = os.path.join(DATA_DIR, \"features.npy\")\n",
    "pred_probs_path = os.path.join(DATA_DIR, \"pred_probs.npy\")\n",
    "\n",
    "np.save(features_path, features)\n",
    "np.save(pred_probs_path, pred_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
