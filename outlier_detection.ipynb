{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36babba0",
   "metadata": {},
   "source": [
    "# Outlier detection in cifar10 dataset using ``Annoy`` and ``Autogluon``\n",
    "\n",
    "This tutorial will show you how to extend outliers detection with Cleanlab's ``get_outlier_scores()`` function to better KNN implementations outside of the ``sklearn`` library. This tutorial focuses on using a subclass of ``sklearn.neighbors.NearestNeighbors`` model, ``Annoy`` but any subclass works as long as ``NearestNeighbors`` can return an array of nearest neighbor distances. This can be done with cleanlab's ``get_outlier_scores()`` function, which takes in the following parameters:\n",
    "\n",
    "- Feature array of shape ``(N, M)``, where N is the number of examples and M is the number of features used to represent each example.\n",
    "- The ``sklearn.neighbors.NearestNeighbors`` object or subclass of ``sklearn.neighbors.NearestNeighbors`` that's been fitted on a dataset in the same feature space.\n",
    "- ``k`` the number of neighbors and ``t`` the rescaling factor for the outlier scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b228267",
   "metadata": {},
   "source": [
    "## 1. Load packages and set seeds for reprodusability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa8b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulyana/virtual/multi/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ulyana/virtual/multi/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ulyana/virtual/multi/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_outlier_scores' from 'cleanlab.rank' (/home/ulyana/virtual/multi/lib/python3.8/site-packages/cleanlab/rank.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcleanlab\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcleanlab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrank\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_outlier_scores\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# from sklearn.neighbors import NearestNeighbors # import KNN estimator\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_outlier_scores' from 'cleanlab.rank' (/home/ulyana/virtual/multi/lib/python3.8/site-packages/cleanlab/rank.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "import warnings\n",
    "\n",
    "import cleanlab\n",
    "from cleanlab.rank import get_outlier_scores\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "# from sklearn.neighbors import NearestNeighbors # import KNN estimator\n",
    "import timm # resnet50 pre-trained model\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e74b5",
   "metadata": {},
   "source": [
    "## 2. Fetch and scale the Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3ede3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 170498071/170498071 [00:02<00:00, 71762021.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Trainset length: 30000\n",
      "Testset length: 10000\n"
     ]
    }
   ],
   "source": [
    "# Select how to load the cifar10 data. Load into tensors for training and normalize range 0-1\n",
    "transform_normalize = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "# Load cifar10 datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_normalize)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_normalize)\n",
    "\n",
    "# Manually remove non-animals out of the training dataset\n",
    "animal_labels = [2,3,4,5,6,7]\n",
    "trainy = trainset.targets # get labels\n",
    "animal_idxs = np.where(np.isin(trainy, animal_labels))[0] # find idx of animals\n",
    "trainset  = torch.utils.data.Subset(trainset, animal_idxs) # select only animals for the train set\n",
    "\n",
    "# Check the shapes of our training and test sets\n",
    "print('Trainset length: %s' % (len(trainset)))\n",
    "print('Testset length: %s' % (len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6e85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for more efficient data streaming to the model\n",
    "batch_size = 50\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf3b58",
   "metadata": {},
   "source": [
    "## 3. Create and train a model\n",
    "The model we are creating is a Swin Transformer using the ``autogluon`` image predictor library.\n",
    "\n",
    "We pass in the images into the model to generate embeddings in the feature space that we require as inputs for the outlier detection algorithm. The model in this tutorial comes from``autogluon.vision`` but outlier detection can be done with any method capable of generating feature embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f95713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImagePredictor sets accuracy as default eval_metric for classification problems.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to process dataset of type: <class 'torch.utils.data.dataloader.DataLoader'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImagePredictor(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# train model [mini_train vs full train + fix epochs and time_limit]\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngpus_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mholdout_frac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12345\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtual/multi/lib/python3.8/site-packages/autogluon/vision/configs/presets_configs.py:18\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m set_presets(preset_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virtual/multi/lib/python3.8/site-packages/autogluon/vision/predictor/predictor.py:308\u001b[0m, in \u001b[0;36mImagePredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`tuning_data` \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtuning_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not among valid list \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# data sanity check\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m _get_valid_labels(train_data)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_cleaner \u001b[38;5;241m=\u001b[39m LabelCleaner\u001b[38;5;241m.\u001b[39mconstruct(problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_problem_type, y\u001b[38;5;241m=\u001b[39mtrain_labels, y_uncleaned\u001b[38;5;241m=\u001b[39mtrain_labels)\n",
      "File \u001b[0;32m~/virtual/multi/lib/python3.8/site-packages/autogluon/vision/predictor/predictor.py:459\u001b[0m, in \u001b[0;36mImagePredictor._validate_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(err_msg)\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to process dataset of type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ImageClassification\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_inner \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to process dataset of type: <class 'torch.utils.data.dataloader.DataLoader'>"
     ]
    }
   ],
   "source": [
    "from autogluon.vision import ImagePredictor, ImageDataset\n",
    "\n",
    "# Train and save trained model-- only works on remote server!\n",
    "model_name = 'swin_base_patch4_window7_224' # or resnet50\n",
    "\n",
    "# init model\n",
    "model = ImagePredictor(verbosity=2)\n",
    "\n",
    "# train model [mini_train vs full train + fix epochs and time_limit]\n",
    "model.fit(\n",
    "    train_data=trainloader,\n",
    "    ngpus_per_trial=1,\n",
    "    hyperparameters={\"holdout_frac\": 0.2, \"model\": model_name},\n",
    "    time_limit=18000,\n",
    "    random_state=12345,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab0b36",
   "metadata": {},
   "source": [
    "## 4. Get model embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880db675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can take ~1-2 mins\n",
    "train_feature_embeddings = []\n",
    "\n",
    "for data in trainloader:\n",
    "    images, labels = data\n",
    "    feature_embeddings = model(images) # Generate feature embeddings of the training data using the model\n",
    "    train_feature_embeddings.extend(feature_embeddings.detach().numpy())\n",
    "train_feature_embeddings = np.array(train_feature_embeddings)\n",
    "print(f'Train embeddings pooled shape: {train_feature_embeddings.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
