{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating a standard Active Learning pipeline\n",
    "Train accurate classifier models with minimal data labeling (and minimal code) via active learning and AutoML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/examples/blob/master/active_learning_single_annotator/active_learning_single_annotator.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a practical approach to efficiently label data for training an accurate image classifier via active learning and AutoML. We consider standard active learning settings with a pool of unlabeled examples, where we label a batch of examples at a time and collect **at most one label** per example. If your data labeling may be noisy (imperfect), the consider our **active_learning_multiannotator** notebook instead, which helps you decide what data to re-label during active learning.\n",
    "\n",
    "In **Active Learning**, we aim to construct a labeled dataset by collecting the fewest labels that still allow us to train an accurate classifier model. Here we assume data labeling is done in **batches**, and between these data labeling rounds, we retrain our classifier to decide what previously unlabeled examples (i.e. datapoints) to label next round.\n",
    "\n",
    "\n",
    "This notebook demonstrates how to compute these scores easily for use in sequential active learning, showing how a classification model iteratively improves after labeling more examples for multiple rounds with the following steps:\n",
    "\n",
    "1. Establish an initially labeled dataset, `df_labeled` to train the model on. This is a small subset of our training data, `df_train`. The rest of the training data is marked as `df_unlabeled`.\n",
    "2. Train the model on the available labeled data and get predictions for the unlabeled data, `pred_probs_unlabeled`.\n",
    "3. Compute active learning scores for all unlabeled examples and select which samples to collect labels for.\n",
    "4. Label the selected samples and add them to current training set.\n",
    "5. Repeat steps 2-4 to collect as many labels as your budget permits.\n",
    "\n",
    "The accuracy of the model trained on the resulting dataset will generally match that of the same model trained on a much larger set of randomly selected examples -- i.e. this is the cheapest way to grow a dataset for training an accurate classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and data\n",
    "\n",
    "Here we use images from the [Caltech-256](https://data.caltech.edu/records/nyy15-4j048) [1] classification dataset. Any image dataset in the same format can be substituted instead and the same code should work. The active learning method demonstrated here works for any classification data (text, tabular, audio, etc.) as long as you are able to train a ML model on the labeled subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from gluoncv.auto.data.dataset import ImageClassificationDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cleanlab.multiannotator import get_label_quality_scores, get_active_learning_scores\n",
    "from utils.model_training_autogluon import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘256_ObjectCategories.zip’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc 'https://cleanlab-public.s3.amazonaws.com/ActiveLearning/Caltech256/256_ObjectCategories.zip' && unzip -o -q 256_ObjectCategories.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select initial labeled dataset\n",
    "We load our data file into a variable called `dataset`. This is a DataFrame containing labels and file paths for each image (i.e. example) from Caltech-256\n",
    "\n",
    "We then randomly split the dataset into train and test splits. Test data are just used here to demonstrate the accuracy in our model after each active learning round (you may not have any test data in your applications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageClassificationDataset.from_folder('./256_ObjectCategories/')\n",
    "dataset = dataset.replace(257, 256) # no class class in dataset is labeled as 257, we need to reindex\n",
    "\n",
    "# Split data into train and test\n",
    "df_train, df_test = train_test_split(dataset, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data are further split into labeled and unlabeled pools. `df_labeled` represents our initial labeled dataset which we use to train an initial classifier model (in your application, this would be all the labeled data you have). `df_unlabeled` represents our unlabeled pool of examples we could consider labeling. In this example, we technically know all the labels for these images too -- given they all come from Caltech-256 -- but we demonstrate how active learning would work in your applications by assuming we don't know their labels. In each active learning round, we only reveal the label of specific images the algorithm decides to collect labels for.\n",
    "\n",
    "In this demonstration, our initial training set (`df_labeled`) has 8 labeled images from each class, which is not enough data to train a good classifier. The goal is to grow this dataset with the fewest number of additional labeled examples that suffice to train an accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled(dataset,  num_labeled_per_class=8):\n",
    "    \"\"\"Splits provided dataset into two datasets. With df_labeled containing num_labeled_per_class labeles for \n",
    "    each class and df_unlabeled containing the rest of the rows in dataset\"\"\"\n",
    "    \n",
    "    df_labeled = dataset.groupby(\"label\").sample(n=num_labeled_per_class, random_state=123)\n",
    "    labeled_index = list(df_labeled.index)\n",
    "    unlabeled_index = [i for i in range(len(dataset)) if i not in labeled_index]\n",
    "    df_unlabeled = dataset.iloc[unlabeled_index]\n",
    "    df_unlabeled = df_unlabeled.reset_index(drop=True)\n",
    "    df_labeled = df_labeled.reset_index(drop=True)    \n",
    "    return df_labeled, df_unlabeled\n",
    "\n",
    "# Split the train data into labeled and unlabeled with 8 labeled per each class\n",
    "df_labeled, df_unlabeled = get_labeled(df_train, num_labeled_per_class=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on labeled data and get predicted class probabilites for unlabeled data\n",
    "\n",
    "The first step of the active learning pipeline is to train your model on the available labeled data. Next we ask the trained model for its predictions on the unlabeled data -- specifically the predicted probability of each class for each unlabeled example. The `train()` function below returns our `predictor` fitted to `df_labeled`. To use a different type of model, modify this `train()` function as needed. All you need to run active learning with cleanlab is code to: (1) train your model on the labeled data, (2) get its predicted class probabilities for the unlabeled data, (3) collect labels for the examples with the lowest active learning scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_165545/\"\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|█████████████████████████▉                                                    | 103/310 [00:13<00:27,  7.58it/s, loss=5.58, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▏                                                   | 104/310 [00:13<00:27,  7.52it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▍                                                   | 105/310 [00:13<00:27,  7.56it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▋                                                   | 106/310 [00:13<00:26,  7.61it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|██████████████████████████▉                                                   | 107/310 [00:13<00:26,  7.65it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▏                                                  | 108/310 [00:14<00:26,  7.70it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▍                                                  | 109/310 [00:14<00:25,  7.74it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▋                                                  | 110/310 [00:14<00:25,  7.78it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 111/310 [00:14<00:25,  7.83it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 112/310 [00:14<00:25,  7.87it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▍                                                 | 113/310 [00:14<00:24,  7.91it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 114/310 [00:14<00:24,  7.95it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 115/310 [00:14<00:24,  7.99it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████▏                                                | 116/310 [00:14<00:24,  8.03it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▍                                                | 117/310 [00:14<00:23,  8.07it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▋                                                | 118/310 [00:14<00:23,  8.11it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▉                                                | 119/310 [00:14<00:23,  8.15it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▏                                               | 120/310 [00:14<00:23,  8.19it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▍                                               | 121/310 [00:14<00:22,  8.23it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▋                                               | 122/310 [00:14<00:22,  8.27it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▉                                               | 123/310 [00:14<00:22,  8.31it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▏                                              | 124/310 [00:14<00:22,  8.35it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▍                                              | 125/310 [00:14<00:22,  8.39it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▋                                              | 126/310 [00:14<00:21,  8.43it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▉                                              | 127/310 [00:14<00:21,  8.47it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▏                                             | 128/310 [00:15<00:21,  8.51it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▍                                             | 129/310 [00:15<00:21,  8.54it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▋                                             | 130/310 [00:15<00:20,  8.58it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▉                                             | 131/310 [00:15<00:20,  8.62it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▏                                            | 132/310 [00:15<00:20,  8.66it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 133/310 [00:15<00:20,  8.69it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 134/310 [00:15<00:20,  8.73it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  44%|█████████████████████████████████▉                                            | 135/310 [00:15<00:19,  8.77it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 136/310 [00:15<00:19,  8.80it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▍                                           | 137/310 [00:15<00:19,  8.84it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▋                                           | 138/310 [00:15<00:19,  8.87it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▉                                           | 139/310 [00:15<00:19,  8.91it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▏                                          | 140/310 [00:15<00:19,  8.94it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 141/310 [00:15<00:18,  8.98it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 142/310 [00:15<00:18,  9.01it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▉                                          | 143/310 [00:15<00:18,  9.04it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▏                                         | 144/310 [00:15<00:18,  9.08it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▍                                         | 145/310 [00:15<00:18,  9.11it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▋                                         | 146/310 [00:15<00:17,  9.14it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▉                                         | 147/310 [00:16<00:17,  9.18it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▏                                        | 148/310 [00:16<00:17,  9.21it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▍                                        | 149/310 [00:16<00:17,  9.24it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▋                                        | 150/310 [00:16<00:17,  9.27it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  49%|█████████████████████████████████████▉                                        | 151/310 [00:16<00:17,  9.31it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▏                                       | 152/310 [00:16<00:16,  9.34it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▍                                       | 153/310 [00:16<00:16,  9.37it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▋                                       | 154/310 [00:16<00:16,  9.40it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████                                       | 155/310 [00:16<00:16,  9.44it/s, loss=5.58, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 6: 'val_accuracy' reached 0.00728 (best 0.00728), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_165545/epoch=0-step=6.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66%|███████████████████████████████████████████████████▊                          | 206/310 [00:29<00:15,  6.89it/s, loss=5.49, v_num=]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time limit reached. Elapsed time is 0:00:30. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████                          | 207/310 [00:30<00:14,  6.89it/s, loss=5.49, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 208/310 [00:30<00:14,  6.87it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████▌                         | 209/310 [00:30<00:14,  6.89it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  68%|████████████████████████████████████████████████████▊                         | 210/310 [00:30<00:14,  6.91it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  68%|█████████████████████████████████████████████████████                         | 211/310 [00:30<00:14,  6.93it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  68%|█████████████████████████████████████████████████████▎                        | 212/310 [00:30<00:14,  6.95it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  69%|█████████████████████████████████████████████████████▌                        | 213/310 [00:30<00:13,  6.98it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  69%|█████████████████████████████████████████████████████▊                        | 214/310 [00:30<00:13,  7.00it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  69%|██████████████████████████████████████████████████████                        | 215/310 [00:30<00:13,  7.02it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  70%|██████████████████████████████████████████████████████▎                       | 216/310 [00:30<00:13,  7.04it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  70%|██████████████████████████████████████████████████████▌                       | 217/310 [00:30<00:13,  7.06it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  70%|██████████████████████████████████████████████████████▊                       | 218/310 [00:30<00:12,  7.08it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  71%|███████████████████████████████████████████████████████                       | 219/310 [00:30<00:12,  7.10it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  71%|███████████████████████████████████████████████████████▎                      | 220/310 [00:30<00:12,  7.12it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  71%|███████████████████████████████████████████████████████▌                      | 221/310 [00:30<00:12,  7.14it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  72%|███████████████████████████████████████████████████████▊                      | 222/310 [00:30<00:12,  7.16it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  72%|████████████████████████████████████████████████████████                      | 223/310 [00:31<00:12,  7.18it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  72%|████████████████████████████████████████████████████████▎                     | 224/310 [00:31<00:11,  7.20it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  73%|████████████████████████████████████████████████████████▌                     | 225/310 [00:31<00:11,  7.22it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  73%|████████████████████████████████████████████████████████▊                     | 226/310 [00:31<00:11,  7.24it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  73%|█████████████████████████████████████████████████████████                     | 227/310 [00:31<00:11,  7.27it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  74%|█████████████████████████████████████████████████████████▎                    | 228/310 [00:31<00:11,  7.29it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  74%|█████████████████████████████████████████████████████████▌                    | 229/310 [00:31<00:11,  7.31it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  74%|█████████████████████████████████████████████████████████▊                    | 230/310 [00:31<00:10,  7.33it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  75%|██████████████████████████████████████████████████████████                    | 231/310 [00:31<00:10,  7.35it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  75%|██████████████████████████████████████████████████████████▎                   | 232/310 [00:31<00:10,  7.37it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  75%|██████████████████████████████████████████████████████████▋                   | 233/310 [00:31<00:10,  7.39it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  75%|██████████████████████████████████████████████████████████▉                   | 234/310 [00:31<00:10,  7.41it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  76%|███████████████████████████████████████████████████████████▏                  | 235/310 [00:31<00:10,  7.42it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  76%|███████████████████████████████████████████████████████████▍                  | 236/310 [00:31<00:09,  7.44it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  76%|███████████████████████████████████████████████████████████▋                  | 237/310 [00:31<00:09,  7.46it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  77%|███████████████████████████████████████████████████████████▉                  | 238/310 [00:31<00:09,  7.48it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  77%|████████████████████████████████████████████████████████████▏                 | 239/310 [00:31<00:09,  7.50it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  77%|████████████████████████████████████████████████████████████▍                 | 240/310 [00:31<00:09,  7.52it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  78%|████████████████████████████████████████████████████████████▋                 | 241/310 [00:31<00:09,  7.54it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  78%|████████████████████████████████████████████████████████████▉                 | 242/310 [00:32<00:08,  7.56it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  78%|█████████████████████████████████████████████████████████████▏                | 243/310 [00:32<00:08,  7.58it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  79%|█████████████████████████████████████████████████████████████▍                | 244/310 [00:32<00:08,  7.60it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  79%|█████████████████████████████████████████████████████████████▋                | 245/310 [00:32<00:08,  7.62it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  79%|█████████████████████████████████████████████████████████████▉                | 246/310 [00:32<00:08,  7.64it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  80%|██████████████████████████████████████████████████████████████▏               | 247/310 [00:32<00:08,  7.66it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  80%|██████████████████████████████████████████████████████████████▍               | 248/310 [00:32<00:08,  7.67it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  80%|██████████████████████████████████████████████████████████████▋               | 249/310 [00:32<00:07,  7.69it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  81%|██████████████████████████████████████████████████████████████▉               | 250/310 [00:32<00:07,  7.71it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  81%|███████████████████████████████████████████████████████████████▏              | 251/310 [00:32<00:07,  7.73it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  81%|███████████████████████████████████████████████████████████████▍              | 252/310 [00:32<00:07,  7.75it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  82%|███████████████████████████████████████████████████████████████▋              | 253/310 [00:32<00:07,  7.77it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  82%|███████████████████████████████████████████████████████████████▉              | 254/310 [00:32<00:07,  7.78it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  82%|████████████████████████████████████████████████████████████████▏             | 255/310 [00:32<00:07,  7.80it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  83%|████████████████████████████████████████████████████████████████▍             | 256/310 [00:32<00:06,  7.82it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  83%|████████████████████████████████████████████████████████████████▋             | 257/310 [00:32<00:06,  7.84it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  83%|████████████████████████████████████████████████████████████████▉             | 258/310 [00:32<00:06,  7.86it/s, loss=5.49, v_num=]\u001b[A\n",
      "Epoch 0:  84%|█████████████████████████████████████████████████████████████████▏            | 259/310 [00:32<00:06,  7.88it/s, loss=5.49, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 9: 'val_accuracy' reached 0.00971 (best 0.00971), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_165545/epoch=0-step=9.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  84%|█████████████████████████████████████████████████████████████████▏            | 259/310 [00:47<00:09,  5.41it/s, loss=5.49, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.64it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.72it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_165545 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 597/597 [01:42<00:00,  5.84it/s]\n"
     ]
    }
   ],
   "source": [
    "predictor = train(df_labeled, out_folder=None, time_limit=30)\n",
    "pred_probs_unlabeled = predictor.predict_proba(df_unlabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain active learning scores for the unlabeled data\n",
    "\n",
    "Using these predicted class probabilities, you should next compute active learning scores that estimate the informativeness of labeling each datapoint. Since we will collect at most one annotation per example in this pipeline, we only care about scoring the unlabeled data.\n",
    "\n",
    "These active learning scores represent how confident our model is about an example's true label based on the currently obtained annotations; examples with the lowest scores are those for which additional labels should be collected (i.e. likely the most informative). These scores are estimated via [ActiveLab](https://arxiv.org/abs/2301.11856), an algorithm developed by the Cleanlab team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "# compute active learning scores\n",
    "_, active_learning_scores_unlabeled = get_active_learning_scores(\n",
    "    df_labeled['label'].to_numpy(), pred_probs_unlabeled=pred_probs_unlabeled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00742915, 0.00528911, 0.00507766, 0.00588142, 0.00631748])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print active learning scores for the first 5 examples in the unlabeld pool:\n",
    "active_learning_scores_unlabeled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get index to relabel\n",
    "\n",
    "Subsequently, rank the unlabeled examples by their active learning scores, and obtain the indices of examples with the lowest scores. These are the **unlabeled** examples whose true label our current model is least confident about. You should prioritize these examples for labeling next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_to_label(active_learning_scores_unlabeled, batch_size_to_label):\n",
    "    \"\"\"Function to get indices of examples with the lowest active learning score to collect more labels for.\"\"\"\n",
    "    \n",
    "    return np.argsort(active_learning_scores_unlabeled)[:batch_size_to_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7928,  9244,  3141, 11455,  1645]),\n",
       " array([0.00469176, 0.00472476, 0.00474545, 0.00476181, 0.00477689]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size_to_label = 100  # you can pick how many examples to collect more labels for at each round, depending on your setup\n",
    "\n",
    "# get next idx to label based on batch_size_to_label and magnitude of each example's active learning score\n",
    "next_idx_to_label = get_idx_to_label(active_learning_scores_unlabeled, batch_size_to_label=batch_size_to_label)\n",
    "next_idx_to_label[:5],active_learning_scores_unlabeled[next_idx_to_label[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving model accuracy over 15 rounds of active learning (collecting new labels) \n",
    "\n",
    "The code below shows a full demonstration of how we can **repeatedly** use the above methods to: select which examples to collect labels for next, add their labels to the current training dataset, and train an improved classifier model.\n",
    "\n",
    "Here we run 10 rounds of this active learning loop, choosing 100 new unlabeled examples to label in each round. In your applications, you will need to replace the code we used here to reveal the labels of new examples.\n",
    "\n",
    "[Optional step] After each round, we also report the current model's accuracy on our held-out test dataset (you may not have test data in your applications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_next_iter_data(df_labeled, df_unlabeled, relabel_idx_unlabeled):\n",
    "    \"\"\"Updates inputs after additional labels have been collected in a single active learning round,\n",
    "    this ensures that the inputs will be well formatted for the next round of active learning.\"\"\"\n",
    "\n",
    "    df_labeled = pd.concat([df_labeled,df_unlabeled.iloc[relabel_idx_unlabeled]], ignore_index=True)\n",
    "    df_unlabeled = df_unlabeled.drop(relabel_idx_unlabeled)\n",
    "    df_unlabeled = df_unlabeled.reset_index(drop=True)\n",
    "    df_labeled = df_labeled.reset_index(drop=True)  \n",
    "    return df_labeled, df_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 20\n",
    "batch_size_to_label = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_205347/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|█████████████████████████▉                                                    | 103/310 [00:13<00:27,  7.48it/s, loss=5.58, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▏                                                   | 104/310 [00:14<00:28,  7.32it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▍                                                   | 105/310 [00:14<00:27,  7.37it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▋                                                   | 106/310 [00:14<00:27,  7.41it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|██████████████████████████▉                                                   | 107/310 [00:14<00:27,  7.45it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▏                                                  | 108/310 [00:14<00:26,  7.50it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▍                                                  | 109/310 [00:14<00:26,  7.54it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▋                                                  | 110/310 [00:14<00:26,  7.58it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 111/310 [00:14<00:26,  7.62it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 112/310 [00:14<00:25,  7.67it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▍                                                 | 113/310 [00:14<00:25,  7.71it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 114/310 [00:14<00:25,  7.75it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 115/310 [00:14<00:25,  7.79it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████▏                                                | 116/310 [00:14<00:24,  7.83it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▍                                                | 117/310 [00:14<00:24,  7.87it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▋                                                | 118/310 [00:14<00:24,  7.91it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▉                                                | 119/310 [00:14<00:24,  7.95it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▏                                               | 120/310 [00:15<00:23,  7.99it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▍                                               | 121/310 [00:15<00:23,  8.03it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▋                                               | 122/310 [00:15<00:23,  8.07it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▉                                               | 123/310 [00:15<00:23,  8.11it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▏                                              | 124/310 [00:15<00:22,  8.15it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▍                                              | 125/310 [00:15<00:22,  8.18it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▋                                              | 126/310 [00:15<00:22,  8.22it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▉                                              | 127/310 [00:15<00:22,  8.26it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▏                                             | 128/310 [00:15<00:21,  8.30it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▍                                             | 129/310 [00:15<00:21,  8.34it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▋                                             | 130/310 [00:15<00:21,  8.37it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▉                                             | 131/310 [00:15<00:21,  8.41it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▏                                            | 132/310 [00:15<00:21,  8.45it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 133/310 [00:15<00:20,  8.48it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 134/310 [00:15<00:20,  8.52it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  44%|█████████████████████████████████▉                                            | 135/310 [00:15<00:20,  8.55it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 136/310 [00:15<00:20,  8.59it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▍                                           | 137/310 [00:15<00:20,  8.63it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▋                                           | 138/310 [00:15<00:19,  8.66it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▉                                           | 139/310 [00:15<00:19,  8.70it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▏                                          | 140/310 [00:16<00:19,  8.73it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 141/310 [00:16<00:19,  8.76it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 142/310 [00:16<00:19,  8.80it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▉                                          | 143/310 [00:16<00:18,  8.83it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▏                                         | 144/310 [00:16<00:18,  8.87it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▍                                         | 145/310 [00:16<00:18,  8.90it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▋                                         | 146/310 [00:16<00:18,  8.93it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▉                                         | 147/310 [00:16<00:18,  8.97it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▏                                        | 148/310 [00:16<00:18,  9.00it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▍                                        | 149/310 [00:16<00:17,  9.03it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▋                                        | 150/310 [00:16<00:17,  9.06it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  49%|█████████████████████████████████████▉                                        | 151/310 [00:16<00:17,  9.10it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▏                                       | 152/310 [00:16<00:17,  9.13it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▍                                       | 153/310 [00:16<00:17,  9.16it/s, loss=5.58, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▋                                       | 154/310 [00:16<00:16,  9.20it/s, loss=5.58, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████                                       | 155/310 [00:16<00:16,  9.23it/s, loss=5.58, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 6: 'val_accuracy' reached 0.00728 (best 0.00728), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_205347/epoch=0-step=6.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:31. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████▎                                      | 156/310 [00:31<00:31,  4.96it/s, loss=5.59, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/52 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▌                                      | 157/310 [00:31<00:31,  4.91it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▊                                      | 158/310 [00:32<00:30,  4.93it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████████████████                                      | 159/310 [00:32<00:30,  4.96it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▎                                     | 160/310 [00:32<00:30,  4.98it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▌                                     | 161/310 [00:32<00:29,  5.00it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▊                                     | 162/310 [00:32<00:29,  5.02it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████                                     | 163/310 [00:32<00:29,  5.05it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▎                                    | 164/310 [00:32<00:28,  5.07it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▌                                    | 165/310 [00:32<00:28,  5.09it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▊                                    | 166/310 [00:32<00:28,  5.12it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████                                    | 167/310 [00:32<00:27,  5.14it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▎                                   | 168/310 [00:32<00:27,  5.16it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▌                                   | 169/310 [00:32<00:27,  5.18it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▊                                   | 170/310 [00:32<00:26,  5.21it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████                                   | 171/310 [00:32<00:26,  5.23it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████▎                                  | 172/310 [00:32<00:26,  5.25it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▌                                  | 173/310 [00:32<00:25,  5.27it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▊                                  | 174/310 [00:32<00:25,  5.29it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  56%|████████████████████████████████████████████                                  | 175/310 [00:32<00:25,  5.32it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▎                                 | 176/310 [00:32<00:25,  5.34it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▌                                 | 177/310 [00:33<00:24,  5.36it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▊                                 | 178/310 [00:33<00:24,  5.38it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████                                 | 179/310 [00:33<00:24,  5.40it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▎                                | 180/310 [00:33<00:23,  5.43it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▌                                | 181/310 [00:33<00:23,  5.45it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▊                                | 182/310 [00:33<00:23,  5.47it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████                                | 183/310 [00:33<00:23,  5.49it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▎                               | 184/310 [00:33<00:22,  5.51it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▌                               | 185/310 [00:33<00:22,  5.53it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▊                               | 186/310 [00:33<00:22,  5.55it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████                               | 187/310 [00:33<00:22,  5.58it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▎                              | 188/310 [00:33<00:21,  5.60it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▌                              | 189/310 [00:33<00:21,  5.62it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▊                              | 190/310 [00:33<00:21,  5.64it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████                              | 191/310 [00:33<00:21,  5.66it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▎                             | 192/310 [00:33<00:20,  5.68it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▌                             | 193/310 [00:33<00:20,  5.70it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▊                             | 194/310 [00:33<00:20,  5.72it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████                             | 195/310 [00:33<00:20,  5.74it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▎                            | 196/310 [00:34<00:19,  5.76it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▌                            | 197/310 [00:34<00:19,  5.79it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▊                            | 198/310 [00:34<00:19,  5.81it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████                            | 199/310 [00:34<00:19,  5.83it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▎                           | 200/310 [00:34<00:18,  5.85it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▌                           | 201/310 [00:34<00:18,  5.87it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▊                           | 202/310 [00:34<00:18,  5.89it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  65%|███████████████████████████████████████████████████                           | 203/310 [00:34<00:18,  5.91it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▎                          | 204/310 [00:34<00:17,  5.93it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 205/310 [00:34<00:17,  5.95it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▊                          | 206/310 [00:34<00:17,  5.97it/s, loss=5.59, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████                          | 207/310 [00:34<00:17,  5.99it/s, loss=5.59, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 208/310 [00:34<00:16,  6.01it/s, loss=5.59, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 6: 'val_accuracy' reached 0.00728 (best 0.00728), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_205347/epoch=0-step=6-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 208/310 [00:53<00:26,  3.90it/s, loss=5.59, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.53it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.57it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_205347 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 597/597 [01:43<00:00,  5.80it/s]\n",
      "predicting class labels for test split\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 316/316 [00:56<00:00,  5.63it/s]\n",
      "test round:  0 accuracy:  0.005148005148005148\n",
      "computing active learning scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n",
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_205805/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting idx to relabel\n",
      "setting up next iter\n",
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|██████████████████████████                                                    | 108/324 [00:15<00:30,  7.17it/s, loss=5.57, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▏                                                   | 109/324 [00:15<00:30,  7.03it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▍                                                   | 110/324 [00:15<00:30,  7.07it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▋                                                   | 111/324 [00:15<00:29,  7.11it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  35%|██████████████████████████▉                                                   | 112/324 [00:15<00:29,  7.15it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▏                                                  | 113/324 [00:15<00:29,  7.19it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▍                                                  | 114/324 [00:15<00:29,  7.23it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▋                                                  | 115/324 [00:15<00:28,  7.27it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 116/324 [00:15<00:28,  7.31it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 117/324 [00:15<00:28,  7.35it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▍                                                 | 118/324 [00:15<00:27,  7.39it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 119/324 [00:16<00:27,  7.42it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 120/324 [00:16<00:27,  7.46it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████▏                                                | 121/324 [00:16<00:27,  7.50it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▎                                                | 122/324 [00:16<00:26,  7.54it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▌                                                | 123/324 [00:16<00:26,  7.57it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▊                                                | 124/324 [00:16<00:26,  7.61it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████                                                | 125/324 [00:16<00:26,  7.65it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▎                                               | 126/324 [00:16<00:25,  7.68it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▌                                               | 127/324 [00:16<00:25,  7.72it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▊                                               | 128/324 [00:16<00:25,  7.76it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████                                               | 129/324 [00:16<00:25,  7.79it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▎                                              | 130/324 [00:16<00:24,  7.83it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▌                                              | 131/324 [00:16<00:24,  7.86it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▊                                              | 132/324 [00:16<00:24,  7.90it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████                                              | 133/324 [00:16<00:24,  7.93it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▎                                             | 134/324 [00:16<00:23,  7.97it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▌                                             | 135/324 [00:16<00:23,  8.00it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▋                                             | 136/324 [00:16<00:23,  8.04it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▉                                             | 137/324 [00:16<00:23,  8.07it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▏                                            | 138/324 [00:17<00:22,  8.10it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 139/324 [00:17<00:22,  8.14it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 140/324 [00:17<00:22,  8.17it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  44%|█████████████████████████████████▉                                            | 141/324 [00:17<00:22,  8.20it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 142/324 [00:17<00:22,  8.24it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▍                                           | 143/324 [00:17<00:21,  8.27it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▋                                           | 144/324 [00:17<00:21,  8.30it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▉                                           | 145/324 [00:17<00:21,  8.34it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▏                                          | 146/324 [00:17<00:21,  8.37it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 147/324 [00:17<00:21,  8.40it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 148/324 [00:17<00:20,  8.43it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▊                                          | 149/324 [00:17<00:20,  8.46it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████                                          | 150/324 [00:17<00:20,  8.49it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▎                                         | 151/324 [00:17<00:20,  8.53it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▌                                         | 152/324 [00:17<00:20,  8.56it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▊                                         | 153/324 [00:17<00:19,  8.59it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████                                         | 154/324 [00:17<00:19,  8.62it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▎                                        | 155/324 [00:17<00:19,  8.65it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▌                                        | 156/324 [00:17<00:19,  8.68it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▊                                        | 157/324 [00:18<00:19,  8.71it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████                                        | 158/324 [00:18<00:18,  8.74it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▎                                       | 159/324 [00:18<00:18,  8.77it/s, loss=5.57, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  49%|██████████████████████████████████████▌                                       | 160/324 [00:18<00:18,  8.80it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▊                                       | 161/324 [00:18<00:18,  8.83it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████                                       | 162/324 [00:18<00:18,  8.86it/s, loss=5.57, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 6: 'val_accuracy' reached 0.01157 (best 0.01157), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_205805/epoch=0-step=6.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:32. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████▏                                      | 163/324 [00:32<00:32,  4.94it/s, loss=5.57, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▍                                      | 164/324 [00:33<00:32,  4.91it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▋                                      | 165/324 [00:33<00:32,  4.93it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▉                                      | 166/324 [00:33<00:31,  4.95it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▏                                     | 167/324 [00:33<00:31,  4.97it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▍                                     | 168/324 [00:33<00:31,  4.99it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▋                                     | 169/324 [00:33<00:30,  5.02it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▉                                     | 170/324 [00:33<00:30,  5.04it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▏                                    | 171/324 [00:33<00:30,  5.06it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▍                                    | 172/324 [00:33<00:29,  5.08it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▋                                    | 173/324 [00:33<00:29,  5.10it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▉                                    | 174/324 [00:33<00:29,  5.13it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▏                                   | 175/324 [00:33<00:28,  5.15it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▎                                   | 176/324 [00:34<00:28,  5.17it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▌                                   | 177/324 [00:34<00:28,  5.19it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▊                                   | 178/324 [00:34<00:28,  5.21it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████                                   | 179/324 [00:34<00:27,  5.23it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▎                                  | 180/324 [00:34<00:27,  5.25it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▌                                  | 181/324 [00:34<00:27,  5.28it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▊                                  | 182/324 [00:34<00:26,  5.30it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|████████████████████████████████████████████                                  | 183/324 [00:34<00:26,  5.32it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▎                                 | 184/324 [00:34<00:26,  5.34it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▌                                 | 185/324 [00:34<00:25,  5.36it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▊                                 | 186/324 [00:34<00:25,  5.38it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████                                 | 187/324 [00:34<00:25,  5.40it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▎                                | 188/324 [00:34<00:25,  5.42it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▌                                | 189/324 [00:34<00:24,  5.44it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▋                                | 190/324 [00:34<00:24,  5.46it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▉                                | 191/324 [00:34<00:24,  5.48it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▏                               | 192/324 [00:34<00:23,  5.50it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▍                               | 193/324 [00:34<00:23,  5.52it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▋                               | 194/324 [00:34<00:23,  5.55it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▉                               | 195/324 [00:35<00:23,  5.57it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████▏                              | 196/324 [00:35<00:22,  5.59it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▍                              | 197/324 [00:35<00:22,  5.61it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▋                              | 198/324 [00:35<00:22,  5.63it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▉                              | 199/324 [00:35<00:22,  5.65it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▏                             | 200/324 [00:35<00:21,  5.67it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▍                             | 201/324 [00:35<00:21,  5.69it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▋                             | 202/324 [00:35<00:21,  5.71it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▊                             | 203/324 [00:35<00:21,  5.73it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████                             | 204/324 [00:35<00:20,  5.75it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▎                            | 205/324 [00:35<00:20,  5.76it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▌                            | 206/324 [00:35<00:20,  5.78it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▊                            | 207/324 [00:35<00:20,  5.80it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████                            | 208/324 [00:35<00:19,  5.82it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▎                           | 209/324 [00:35<00:19,  5.84it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▌                           | 210/324 [00:35<00:19,  5.86it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▊                           | 211/324 [00:35<00:19,  5.88it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|███████████████████████████████████████████████████                           | 212/324 [00:35<00:18,  5.90it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▎                          | 213/324 [00:35<00:18,  5.92it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 214/324 [00:36<00:18,  5.94it/s, loss=5.57, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66%|███████████████████████████████████████████████████▊                          | 215/324 [00:36<00:18,  5.96it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████                          | 216/324 [00:36<00:18,  5.98it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████▏                         | 217/324 [00:36<00:17,  6.00it/s, loss=5.57, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 6: 'val_accuracy' reached 0.01157 (best 0.01157), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_205805/epoch=0-step=6-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████▏                         | 217/324 [00:57<00:28,  3.75it/s, loss=5.57, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.58it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.58it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 14/14 [00:02<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_205805 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 594/594 [01:43<00:00,  5.71it/s]\n",
      "predicting class labels for test split\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 316/316 [00:56<00:00,  5.54it/s]\n",
      "test round:  1 accuracy:  0.004158004158004158\n",
      "computing active learning scores\n",
      "getting idx to relabel\n",
      "setting up next iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n",
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_210223/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|█████████████████████████▉                                                    | 113/340 [00:15<00:32,  7.07it/s, loss=5.56, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▏                                                   | 114/340 [00:16<00:32,  6.93it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▍                                                   | 115/340 [00:16<00:32,  6.97it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▌                                                   | 116/340 [00:16<00:31,  7.01it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▊                                                   | 117/340 [00:16<00:31,  7.05it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████                                                   | 118/340 [00:16<00:31,  7.08it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▎                                                  | 119/340 [00:16<00:31,  7.12it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▌                                                  | 120/340 [00:16<00:30,  7.16it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▊                                                  | 121/340 [00:16<00:30,  7.19it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 122/340 [00:16<00:30,  7.23it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 123/340 [00:16<00:29,  7.27it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▍                                                 | 124/340 [00:16<00:29,  7.30it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 125/340 [00:17<00:29,  7.34it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 126/340 [00:17<00:29,  7.37it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████▏                                                | 127/340 [00:17<00:28,  7.41it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▎                                                | 128/340 [00:17<00:28,  7.44it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▌                                                | 129/340 [00:17<00:28,  7.48it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▊                                                | 130/340 [00:17<00:27,  7.51it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████                                                | 131/340 [00:17<00:27,  7.55it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▎                                               | 132/340 [00:17<00:27,  7.58it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▌                                               | 133/340 [00:17<00:27,  7.61it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▋                                               | 134/340 [00:17<00:26,  7.65it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▉                                               | 135/340 [00:17<00:26,  7.68it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▏                                              | 136/340 [00:17<00:26,  7.72it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▍                                              | 137/340 [00:17<00:26,  7.75it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▋                                              | 138/340 [00:17<00:25,  7.78it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▉                                              | 139/340 [00:17<00:25,  7.82it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████                                              | 140/340 [00:17<00:25,  7.85it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▎                                             | 141/340 [00:17<00:25,  7.88it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▌                                             | 142/340 [00:17<00:25,  7.91it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▊                                             | 143/340 [00:18<00:24,  7.94it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|█████████████████████████████████                                             | 144/340 [00:18<00:24,  7.98it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▎                                            | 145/340 [00:18<00:24,  8.01it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 146/340 [00:18<00:24,  8.04it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 147/340 [00:18<00:23,  8.07it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|█████████████████████████████████▉                                            | 148/340 [00:18<00:23,  8.10it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 149/340 [00:18<00:23,  8.13it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▍                                           | 150/340 [00:18<00:23,  8.16it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▋                                           | 151/340 [00:18<00:23,  8.20it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▊                                           | 152/340 [00:18<00:22,  8.23it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████                                           | 153/340 [00:18<00:22,  8.26it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▎                                          | 154/340 [00:18<00:22,  8.29it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▌                                          | 155/340 [00:18<00:22,  8.32it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▊                                          | 156/340 [00:18<00:22,  8.35it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████                                          | 157/340 [00:18<00:21,  8.38it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▏                                         | 158/340 [00:18<00:21,  8.41it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▍                                         | 159/340 [00:18<00:21,  8.44it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▋                                         | 160/340 [00:18<00:21,  8.47it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▉                                         | 161/340 [00:18<00:21,  8.50it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▏                                        | 162/340 [00:19<00:20,  8.53it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▍                                        | 163/340 [00:19<00:20,  8.56it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▌                                        | 164/340 [00:19<00:20,  8.58it/s, loss=5.56, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  49%|█████████████████████████████████████▊                                        | 165/340 [00:19<00:20,  8.61it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████                                        | 166/340 [00:19<00:20,  8.64it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▎                                       | 167/340 [00:19<00:19,  8.67it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▌                                       | 168/340 [00:19<00:19,  8.70it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▊                                       | 169/340 [00:19<00:19,  8.72it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████                                       | 170/340 [00:19<00:19,  8.76it/s, loss=5.56, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_accuracy' reached 0.00664 (best 0.00664), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_210223/epoch=0-step=7.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:31. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████▏                                      | 171/340 [00:31<00:30,  5.50it/s, loss=5.57, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▍                                      | 172/340 [00:31<00:30,  5.45it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▋                                      | 173/340 [00:31<00:30,  5.48it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▉                                      | 174/340 [00:31<00:30,  5.50it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████████████████▏                                     | 175/340 [00:31<00:29,  5.52it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▍                                     | 176/340 [00:31<00:29,  5.54it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▌                                     | 177/340 [00:31<00:29,  5.56it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▊                                     | 178/340 [00:31<00:28,  5.59it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████                                     | 179/340 [00:31<00:28,  5.61it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▎                                    | 180/340 [00:31<00:28,  5.63it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▌                                    | 181/340 [00:32<00:28,  5.65it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▊                                    | 182/340 [00:32<00:27,  5.67it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▉                                    | 183/340 [00:32<00:27,  5.70it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▏                                   | 184/340 [00:32<00:27,  5.72it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▍                                   | 185/340 [00:32<00:27,  5.74it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▋                                   | 186/340 [00:32<00:26,  5.76it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▉                                   | 187/340 [00:32<00:26,  5.78it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████▏                                  | 188/340 [00:32<00:26,  5.80it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▎                                  | 189/340 [00:32<00:25,  5.83it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▌                                  | 190/340 [00:32<00:25,  5.85it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▊                                  | 191/340 [00:32<00:25,  5.87it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  56%|████████████████████████████████████████████                                  | 192/340 [00:32<00:25,  5.89it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▎                                 | 193/340 [00:32<00:24,  5.91it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▌                                 | 194/340 [00:32<00:24,  5.93it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▋                                 | 195/340 [00:32<00:24,  5.95it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  58%|████████████████████████████████████████████▉                                 | 196/340 [00:32<00:24,  5.97it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▏                                | 197/340 [00:32<00:23,  5.99it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▍                                | 198/340 [00:32<00:23,  6.01it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▋                                | 199/340 [00:32<00:23,  6.04it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▉                                | 200/340 [00:33<00:23,  6.06it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████                                | 201/340 [00:33<00:22,  6.08it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▎                               | 202/340 [00:33<00:22,  6.10it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▌                               | 203/340 [00:33<00:22,  6.12it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▊                               | 204/340 [00:33<00:22,  6.14it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████                               | 205/340 [00:33<00:21,  6.16it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▎                              | 206/340 [00:33<00:21,  6.18it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▍                              | 207/340 [00:33<00:21,  6.20it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▋                              | 208/340 [00:33<00:21,  6.22it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▉                              | 209/340 [00:33<00:20,  6.24it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▏                             | 210/340 [00:33<00:20,  6.26it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▍                             | 211/340 [00:33<00:20,  6.28it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▋                             | 212/340 [00:33<00:20,  6.30it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▊                             | 213/340 [00:33<00:20,  6.32it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████                             | 214/340 [00:33<00:19,  6.34it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▎                            | 215/340 [00:33<00:19,  6.36it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▌                            | 216/340 [00:33<00:19,  6.38it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▊                            | 217/340 [00:33<00:19,  6.40it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████                            | 218/340 [00:33<00:19,  6.42it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████▏                           | 219/340 [00:34<00:18,  6.44it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▍                           | 220/340 [00:34<00:18,  6.46it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▋                           | 221/340 [00:34<00:18,  6.47it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▉                           | 222/340 [00:34<00:18,  6.49it/s, loss=5.57, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66%|███████████████████████████████████████████████████▏                          | 223/340 [00:34<00:17,  6.51it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▍                          | 224/340 [00:34<00:17,  6.53it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 225/340 [00:34<00:17,  6.55it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▊                          | 226/340 [00:34<00:17,  6.57it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████                          | 227/340 [00:34<00:17,  6.59it/s, loss=5.57, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 228/340 [00:34<00:16,  6.61it/s, loss=5.57, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_accuracy' reached 0.00664 (best 0.00664), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_210223/epoch=0-step=7-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 228/340 [00:56<00:27,  4.05it/s, loss=5.57, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.70it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.66it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_210223 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 591/591 [01:44<00:00,  5.66it/s]\n",
      "predicting class labels for test split\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 316/316 [00:53<00:00,  5.87it/s]\n",
      "test round:  2 accuracy:  0.004752004752004752\n",
      "computing active learning scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n",
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_210632/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting idx to relabel\n",
      "setting up next iter\n",
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|██████████████████████████                                                    | 118/354 [00:15<00:31,  7.46it/s, loss=5.56, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▏                                                   | 119/354 [00:16<00:32,  7.32it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▍                                                   | 120/354 [00:16<00:31,  7.34it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▋                                                   | 121/354 [00:16<00:31,  7.37it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▉                                                   | 122/354 [00:16<00:31,  7.41it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████                                                   | 123/354 [00:16<00:31,  7.45it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▎                                                  | 124/354 [00:16<00:30,  7.49it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▌                                                  | 125/354 [00:16<00:30,  7.52it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▊                                                  | 126/354 [00:16<00:30,  7.56it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 127/354 [00:16<00:29,  7.60it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 128/354 [00:16<00:29,  7.63it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▍                                                 | 129/354 [00:16<00:29,  7.67it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 130/354 [00:16<00:29,  7.71it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▊                                                 | 131/354 [00:16<00:28,  7.74it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████                                                 | 132/354 [00:16<00:28,  7.78it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▎                                                | 133/354 [00:17<00:28,  7.81it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▌                                                | 134/354 [00:17<00:28,  7.85it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▋                                                | 135/354 [00:17<00:27,  7.88it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▉                                                | 136/354 [00:17<00:27,  7.92it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▏                                               | 137/354 [00:17<00:27,  7.95it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▍                                               | 138/354 [00:17<00:27,  7.99it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▋                                               | 139/354 [00:17<00:26,  8.02it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▊                                               | 140/354 [00:17<00:26,  8.05it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████                                               | 141/354 [00:17<00:26,  8.09it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▎                                              | 142/354 [00:17<00:26,  8.12it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▌                                              | 143/354 [00:17<00:25,  8.15it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▋                                              | 144/354 [00:17<00:25,  8.19it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▉                                              | 145/354 [00:17<00:25,  8.22it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▏                                             | 146/354 [00:17<00:25,  8.25it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▍                                             | 147/354 [00:17<00:24,  8.29it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▌                                             | 148/354 [00:17<00:24,  8.32it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▊                                             | 149/354 [00:17<00:24,  8.35it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  42%|█████████████████████████████████                                             | 150/354 [00:17<00:24,  8.38it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▎                                            | 151/354 [00:17<00:24,  8.42it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 152/354 [00:17<00:23,  8.45it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 153/354 [00:18<00:23,  8.48it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|█████████████████████████████████▉                                            | 154/354 [00:18<00:23,  8.51it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 155/354 [00:18<00:23,  8.54it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▎                                           | 156/354 [00:18<00:23,  8.57it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▌                                           | 157/354 [00:18<00:22,  8.60it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▊                                           | 158/354 [00:18<00:22,  8.63it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████                                           | 159/354 [00:18<00:22,  8.66it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▎                                          | 160/354 [00:18<00:22,  8.69it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 161/354 [00:18<00:22,  8.73it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 162/354 [00:18<00:21,  8.76it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▉                                          | 163/354 [00:18<00:21,  8.79it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▏                                         | 164/354 [00:18<00:21,  8.82it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▎                                         | 165/354 [00:18<00:21,  8.85it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▌                                         | 166/354 [00:18<00:21,  8.87it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▊                                         | 167/354 [00:18<00:21,  8.90it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  47%|█████████████████████████████████████                                         | 168/354 [00:18<00:20,  8.93it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▏                                        | 169/354 [00:18<00:20,  8.96it/s, loss=5.56, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  48%|█████████████████████████████████████▍                                        | 170/354 [00:18<00:20,  8.99it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▋                                        | 171/354 [00:18<00:20,  9.02it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|█████████████████████████████████████▉                                        | 172/354 [00:19<00:20,  9.05it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████                                        | 173/354 [00:19<00:19,  9.08it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▎                                       | 174/354 [00:19<00:19,  9.11it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▌                                       | 175/354 [00:19<00:19,  9.13it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▊                                       | 176/354 [00:19<00:19,  9.16it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████                                       | 177/354 [00:19<00:19,  9.19it/s, loss=5.56, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_accuracy' reached 0.00424 (best 0.00424), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_210632/epoch=0-step=7.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:30. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████▏                                      | 178/354 [00:30<00:29,  5.92it/s, loss=5.56, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/59 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▍                                      | 179/354 [00:30<00:29,  5.87it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▋                                      | 180/354 [00:30<00:29,  5.88it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▉                                      | 181/354 [00:30<00:29,  5.90it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████████████████                                      | 182/354 [00:30<00:29,  5.92it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▎                                     | 183/354 [00:30<00:28,  5.94it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▌                                     | 184/354 [00:30<00:28,  5.97it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▊                                     | 185/354 [00:30<00:28,  5.99it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  53%|████████████████████████████████████████▉                                     | 186/354 [00:30<00:27,  6.01it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▏                                    | 187/354 [00:30<00:27,  6.03it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▍                                    | 188/354 [00:31<00:27,  6.06it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▋                                    | 189/354 [00:31<00:27,  6.08it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▊                                    | 190/354 [00:31<00:26,  6.10it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████                                    | 191/354 [00:31<00:26,  6.12it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▎                                   | 192/354 [00:31<00:26,  6.14it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▌                                   | 193/354 [00:31<00:26,  6.17it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▋                                   | 194/354 [00:31<00:25,  6.19it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▉                                   | 195/354 [00:31<00:25,  6.21it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████▏                                  | 196/354 [00:31<00:25,  6.23it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▍                                  | 197/354 [00:31<00:25,  6.25it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▋                                  | 198/354 [00:31<00:24,  6.28it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▊                                  | 199/354 [00:31<00:24,  6.30it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  56%|████████████████████████████████████████████                                  | 200/354 [00:31<00:24,  6.32it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▎                                 | 201/354 [00:31<00:24,  6.34it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▌                                 | 202/354 [00:31<00:23,  6.36it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▋                                 | 203/354 [00:31<00:23,  6.38it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  58%|████████████████████████████████████████████▉                                 | 204/354 [00:31<00:23,  6.40it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▏                                | 205/354 [00:31<00:23,  6.42it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▍                                | 206/354 [00:31<00:22,  6.45it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▌                                | 207/354 [00:32<00:22,  6.47it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▊                                | 208/354 [00:32<00:22,  6.49it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████                                | 209/354 [00:32<00:22,  6.51it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▎                               | 210/354 [00:32<00:22,  6.53it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▍                               | 211/354 [00:32<00:21,  6.55it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▋                               | 212/354 [00:32<00:21,  6.57it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▉                               | 213/354 [00:32<00:21,  6.59it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████▏                              | 214/354 [00:32<00:21,  6.61it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▎                              | 215/354 [00:32<00:20,  6.63it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▌                              | 216/354 [00:32<00:20,  6.65it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▊                              | 217/354 [00:32<00:20,  6.67it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████                              | 218/354 [00:32<00:20,  6.69it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▎                             | 219/354 [00:32<00:20,  6.71it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▍                             | 220/354 [00:32<00:19,  6.73it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▋                             | 221/354 [00:32<00:19,  6.75it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▉                             | 222/354 [00:32<00:19,  6.77it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▏                            | 223/354 [00:32<00:19,  6.79it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▎                            | 224/354 [00:32<00:19,  6.81it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▌                            | 225/354 [00:32<00:18,  6.83it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▊                            | 226/354 [00:32<00:18,  6.85it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████                            | 227/354 [00:33<00:18,  6.87it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████▏                           | 228/354 [00:33<00:18,  6.89it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▍                           | 229/354 [00:33<00:18,  6.91it/s, loss=5.56, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  65%|██████████████████████████████████████████████████▋                           | 230/354 [00:33<00:17,  6.93it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▉                           | 231/354 [00:33<00:17,  6.95it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████                           | 232/354 [00:33<00:17,  6.97it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▎                          | 233/354 [00:33<00:17,  6.99it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 234/354 [00:33<00:17,  7.01it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▊                          | 235/354 [00:33<00:16,  7.03it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████                          | 236/354 [00:33<00:16,  7.05it/s, loss=5.56, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████▏                         | 237/354 [00:33<00:16,  7.06it/s, loss=5.56, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_accuracy' reached 0.00424 (best 0.00424), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_210632/epoch=0-step=7-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████▏                         | 237/354 [00:56<00:27,  4.22it/s, loss=5.56, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.66it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.76it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 15/15 [00:02<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_210632 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 587/587 [01:38<00:00,  5.96it/s]\n",
      "predicting class labels for test split\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 316/316 [00:53<00:00,  5.89it/s]\n",
      "test round:  3 accuracy:  0.006237006237006237\n",
      "computing active learning scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n",
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_211035/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting idx to relabel\n",
      "setting up next iter\n",
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|█████████████████████████▉                                                    | 123/370 [00:16<00:33,  7.46it/s, loss=5.54, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▏                                                   | 124/370 [00:16<00:33,  7.33it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▎                                                   | 125/370 [00:16<00:33,  7.37it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▌                                                   | 126/370 [00:17<00:32,  7.40it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▊                                                   | 127/370 [00:17<00:32,  7.44it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|██████████████████████████▉                                                   | 128/370 [00:17<00:32,  7.48it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▏                                                  | 129/370 [00:17<00:32,  7.51it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▍                                                  | 130/370 [00:17<00:31,  7.55it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▌                                                  | 131/370 [00:17<00:31,  7.58it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▊                                                  | 132/370 [00:17<00:31,  7.62it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████                                                  | 133/370 [00:17<00:30,  7.65it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 134/370 [00:17<00:30,  7.69it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▍                                                 | 135/370 [00:17<00:30,  7.72it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 136/370 [00:17<00:30,  7.76it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 137/370 [00:17<00:29,  7.79it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████                                                 | 138/370 [00:17<00:29,  7.83it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▎                                                | 139/370 [00:17<00:29,  7.86it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▌                                                | 140/370 [00:17<00:29,  7.89it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▋                                                | 141/370 [00:17<00:28,  7.93it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▉                                                | 142/370 [00:17<00:28,  7.96it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▏                                               | 143/370 [00:17<00:28,  8.00it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▎                                               | 144/370 [00:17<00:28,  8.03it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▌                                               | 145/370 [00:17<00:27,  8.06it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▊                                               | 146/370 [00:18<00:27,  8.09it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▉                                               | 147/370 [00:18<00:27,  8.12it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▏                                              | 148/370 [00:18<00:27,  8.16it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▍                                              | 149/370 [00:18<00:26,  8.19it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▌                                              | 150/370 [00:18<00:26,  8.22it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▊                                              | 151/370 [00:18<00:26,  8.25it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████                                              | 152/370 [00:18<00:26,  8.28it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▎                                             | 153/370 [00:18<00:26,  8.32it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▍                                             | 154/370 [00:18<00:25,  8.35it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▋                                             | 155/370 [00:18<00:25,  8.38it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▉                                             | 156/370 [00:18<00:25,  8.41it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|█████████████████████████████████                                             | 157/370 [00:18<00:25,  8.44it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▎                                            | 158/370 [00:18<00:25,  8.47it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▌                                            | 159/370 [00:18<00:24,  8.50it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 160/370 [00:18<00:24,  8.53it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|█████████████████████████████████▉                                            | 161/370 [00:18<00:24,  8.56it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 162/370 [00:18<00:24,  8.59it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▎                                           | 163/370 [00:18<00:24,  8.62it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▌                                           | 164/370 [00:18<00:23,  8.65it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▊                                           | 165/370 [00:19<00:23,  8.68it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▉                                           | 166/370 [00:19<00:23,  8.70it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▏                                          | 167/370 [00:19<00:23,  8.73it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 168/370 [00:19<00:23,  8.76it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 169/370 [00:19<00:22,  8.79it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▊                                          | 170/370 [00:19<00:22,  8.82it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████                                          | 171/370 [00:19<00:22,  8.85it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▎                                         | 172/370 [00:19<00:22,  8.88it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▍                                         | 173/370 [00:19<00:22,  8.90it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▋                                         | 174/370 [00:19<00:21,  8.93it/s, loss=5.54, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  47%|████████████████████████████████████▉                                         | 175/370 [00:19<00:21,  8.96it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████                                         | 176/370 [00:19<00:21,  8.99it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▎                                        | 177/370 [00:19<00:21,  9.02it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▌                                        | 178/370 [00:19<00:21,  9.04it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▋                                        | 179/370 [00:19<00:21,  9.07it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|█████████████████████████████████████▉                                        | 180/370 [00:19<00:20,  9.10it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▏                                       | 181/370 [00:19<00:20,  9.12it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▎                                       | 182/370 [00:19<00:20,  9.15it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▌                                       | 183/370 [00:19<00:20,  9.18it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▊                                       | 184/370 [00:19<00:20,  9.21it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████                                       | 185/370 [00:20<00:20,  9.24it/s, loss=5.54, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_accuracy' reached 0.01220 (best 0.01220), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211035/epoch=0-step=7.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:32. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████▏                                      | 186/370 [00:32<00:32,  5.68it/s, loss=5.53, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▍                                      | 187/370 [00:33<00:32,  5.64it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▋                                      | 188/370 [00:33<00:32,  5.66it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▊                                      | 189/370 [00:33<00:31,  5.68it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████████████████                                      | 190/370 [00:33<00:31,  5.70it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▎                                     | 191/370 [00:33<00:31,  5.72it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▍                                     | 192/370 [00:33<00:31,  5.74it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▋                                     | 193/370 [00:33<00:30,  5.76it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▉                                     | 194/370 [00:33<00:30,  5.78it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████                                     | 195/370 [00:33<00:30,  5.80it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▎                                    | 196/370 [00:33<00:29,  5.82it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▌                                    | 197/370 [00:33<00:29,  5.84it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▋                                    | 198/370 [00:33<00:29,  5.87it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▉                                    | 199/370 [00:33<00:29,  5.89it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▏                                   | 200/370 [00:33<00:28,  5.91it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▎                                   | 201/370 [00:33<00:28,  5.93it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▌                                   | 202/370 [00:33<00:28,  5.95it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▊                                   | 203/370 [00:34<00:27,  5.97it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████                                   | 204/370 [00:34<00:27,  5.99it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████▏                                  | 205/370 [00:34<00:27,  6.01it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▍                                  | 206/370 [00:34<00:27,  6.03it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▋                                  | 207/370 [00:34<00:26,  6.05it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▊                                  | 208/370 [00:34<00:26,  6.07it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  56%|████████████████████████████████████████████                                  | 209/370 [00:34<00:26,  6.09it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▎                                 | 210/370 [00:34<00:26,  6.11it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▍                                 | 211/370 [00:34<00:25,  6.13it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▋                                 | 212/370 [00:34<00:25,  6.15it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  58%|████████████████████████████████████████████▉                                 | 213/370 [00:34<00:25,  6.17it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████                                 | 214/370 [00:34<00:25,  6.19it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▎                                | 215/370 [00:34<00:24,  6.21it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▌                                | 216/370 [00:34<00:24,  6.23it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▋                                | 217/370 [00:34<00:24,  6.25it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▉                                | 218/370 [00:34<00:24,  6.27it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▏                               | 219/370 [00:34<00:24,  6.29it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▍                               | 220/370 [00:34<00:23,  6.31it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▌                               | 221/370 [00:34<00:23,  6.32it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▊                               | 222/370 [00:34<00:23,  6.34it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████                               | 223/370 [00:35<00:23,  6.36it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▏                              | 224/370 [00:35<00:22,  6.38it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▍                              | 225/370 [00:35<00:22,  6.40it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▋                              | 226/370 [00:35<00:22,  6.42it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▊                              | 227/370 [00:35<00:22,  6.44it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████                              | 228/370 [00:35<00:21,  6.46it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▎                             | 229/370 [00:35<00:21,  6.48it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▍                             | 230/370 [00:35<00:21,  6.50it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▋                             | 231/370 [00:35<00:21,  6.52it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▉                             | 232/370 [00:35<00:21,  6.53it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████                             | 233/370 [00:35<00:20,  6.55it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▎                            | 234/370 [00:35<00:20,  6.57it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▌                            | 235/370 [00:35<00:20,  6.59it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▊                            | 236/370 [00:35<00:20,  6.61it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▉                            | 237/370 [00:35<00:20,  6.63it/s, loss=5.53, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  64%|██████████████████████████████████████████████████▏                           | 238/370 [00:35<00:19,  6.65it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▍                           | 239/370 [00:35<00:19,  6.66it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▌                           | 240/370 [00:35<00:19,  6.68it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▊                           | 241/370 [00:35<00:19,  6.70it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  65%|███████████████████████████████████████████████████                           | 242/370 [00:36<00:19,  6.72it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▏                          | 243/370 [00:36<00:18,  6.74it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▍                          | 244/370 [00:36<00:18,  6.76it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▋                          | 245/370 [00:36<00:18,  6.77it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▊                          | 246/370 [00:36<00:18,  6.79it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████                          | 247/370 [00:36<00:18,  6.81it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 248/370 [00:36<00:17,  6.83it/s, loss=5.53, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_accuracy' reached 0.01220 (best 0.01220), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211035/epoch=0-step=7-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|████████████████████████████████████████████████████▎                         | 248/370 [00:58<00:28,  4.27it/s, loss=5.53, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.73it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.81it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211035 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 584/584 [01:41<00:00,  5.73it/s]\n",
      "predicting class labels for test split\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 316/316 [00:54<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n",
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_211450/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test round:  4 accuracy:  0.006534006534006534\n",
      "computing active learning scores\n",
      "getting idx to relabel\n",
      "setting up next iter\n",
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  33%|██████████████████████████                                                    | 128/383 [00:17<00:34,  7.47it/s, loss=5.54, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▎                                                   | 129/383 [00:17<00:34,  7.35it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▍                                                   | 130/383 [00:17<00:34,  7.38it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▋                                                   | 131/383 [00:17<00:33,  7.42it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▉                                                   | 132/383 [00:17<00:33,  7.45it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████                                                   | 133/383 [00:17<00:33,  7.49it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▎                                                  | 134/383 [00:17<00:33,  7.52it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▍                                                  | 135/383 [00:17<00:32,  7.56it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▋                                                  | 136/383 [00:17<00:32,  7.59it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 137/383 [00:17<00:32,  7.62it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████                                                  | 138/383 [00:18<00:31,  7.66it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▎                                                 | 139/383 [00:18<00:31,  7.69it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▌                                                 | 140/383 [00:18<00:31,  7.72it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▋                                                 | 141/383 [00:18<00:31,  7.76it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 142/383 [00:18<00:30,  7.79it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████                                                 | 143/383 [00:18<00:30,  7.82it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▎                                                | 144/383 [00:18<00:30,  7.86it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▌                                                | 145/383 [00:18<00:30,  7.89it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▋                                                | 146/383 [00:18<00:29,  7.92it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▉                                                | 147/383 [00:18<00:29,  7.95it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▏                                               | 148/383 [00:18<00:29,  7.99it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▎                                               | 149/383 [00:18<00:29,  8.02it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▌                                               | 150/383 [00:18<00:28,  8.05it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▊                                               | 151/383 [00:18<00:28,  8.08it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▉                                               | 152/383 [00:18<00:28,  8.11it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▏                                              | 153/383 [00:18<00:28,  8.14it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▎                                              | 154/383 [00:18<00:28,  8.17it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▌                                              | 155/383 [00:18<00:27,  8.20it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▊                                              | 156/383 [00:18<00:27,  8.23it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▉                                              | 157/383 [00:18<00:27,  8.26it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▏                                             | 158/383 [00:19<00:27,  8.29it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▍                                             | 159/383 [00:19<00:26,  8.33it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▌                                             | 160/383 [00:19<00:26,  8.36it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▊                                             | 161/383 [00:19<00:26,  8.39it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▉                                             | 162/383 [00:19<00:26,  8.41it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▏                                            | 163/383 [00:19<00:26,  8.44it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 164/383 [00:19<00:25,  8.47it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▌                                            | 165/383 [00:19<00:25,  8.50it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▊                                            | 166/383 [00:19<00:25,  8.53it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████                                            | 167/383 [00:19<00:25,  8.56it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▏                                           | 168/383 [00:19<00:25,  8.59it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▍                                           | 169/383 [00:19<00:24,  8.62it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▌                                           | 170/383 [00:19<00:24,  8.65it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▊                                           | 171/383 [00:19<00:24,  8.68it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████                                           | 172/383 [00:19<00:24,  8.70it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▏                                          | 173/383 [00:19<00:24,  8.73it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 174/383 [00:19<00:23,  8.76it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 175/383 [00:19<00:23,  8.79it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▊                                          | 176/383 [00:19<00:23,  8.81it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████                                          | 177/383 [00:20<00:23,  8.84it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▎                                         | 178/383 [00:20<00:23,  8.87it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▍                                         | 179/383 [00:20<00:22,  8.90it/s, loss=5.54, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  47%|████████████████████████████████████▋                                         | 180/383 [00:20<00:22,  8.92it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▊                                         | 181/383 [00:20<00:22,  8.95it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████                                         | 182/383 [00:20<00:22,  8.98it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▎                                        | 183/383 [00:20<00:22,  9.00it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▍                                        | 184/383 [00:20<00:22,  9.03it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▋                                        | 185/383 [00:20<00:21,  9.06it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|█████████████████████████████████████▉                                        | 186/383 [00:20<00:21,  9.08it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████                                        | 187/383 [00:20<00:21,  9.11it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▎                                       | 188/383 [00:20<00:21,  9.14it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▍                                       | 189/383 [00:20<00:21,  9.16it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▋                                       | 190/383 [00:20<00:20,  9.19it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▉                                       | 191/383 [00:20<00:20,  9.22it/s, loss=5.54, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_accuracy' reached 0.01600 (best 0.01600), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211450/epoch=0-step=8.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:37. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████                                       | 192/383 [00:37<00:36,  5.16it/s, loss=5.54, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████▎                                      | 193/383 [00:37<00:37,  5.13it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▌                                      | 194/383 [00:37<00:36,  5.15it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▋                                      | 195/383 [00:37<00:36,  5.17it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▉                                      | 196/383 [00:37<00:36,  5.19it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  51%|████████████████████████████████████████                                      | 197/383 [00:37<00:35,  5.21it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▎                                     | 198/383 [00:38<00:35,  5.20it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▌                                     | 199/383 [00:38<00:35,  5.22it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▋                                     | 200/383 [00:38<00:34,  5.24it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▉                                     | 201/383 [00:38<00:34,  5.26it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▏                                    | 202/383 [00:38<00:34,  5.28it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▎                                    | 203/383 [00:38<00:33,  5.30it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▌                                    | 204/383 [00:38<00:33,  5.32it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▋                                    | 205/383 [00:38<00:33,  5.33it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▉                                    | 206/383 [00:38<00:33,  5.35it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▏                                   | 207/383 [00:38<00:32,  5.37it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▎                                   | 208/383 [00:38<00:32,  5.39it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▌                                   | 209/383 [00:38<00:32,  5.41it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▊                                   | 210/383 [00:38<00:31,  5.43it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▉                                   | 211/383 [00:38<00:31,  5.45it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████▏                                  | 212/383 [00:38<00:31,  5.47it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▍                                  | 213/383 [00:38<00:30,  5.48it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▌                                  | 214/383 [00:38<00:30,  5.50it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▊                                  | 215/383 [00:38<00:30,  5.52it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▉                                  | 216/383 [00:38<00:30,  5.54it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▏                                 | 217/383 [00:39<00:29,  5.56it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▍                                 | 218/383 [00:39<00:29,  5.58it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▌                                 | 219/383 [00:39<00:29,  5.59it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▊                                 | 220/383 [00:39<00:29,  5.61it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████                                 | 221/383 [00:39<00:28,  5.63it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▏                                | 222/383 [00:39<00:28,  5.65it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▍                                | 223/383 [00:39<00:28,  5.67it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▌                                | 224/383 [00:39<00:27,  5.68it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▊                                | 225/383 [00:39<00:27,  5.70it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████                                | 226/383 [00:39<00:27,  5.72it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▏                               | 227/383 [00:39<00:27,  5.74it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▍                               | 228/383 [00:39<00:26,  5.76it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▋                               | 229/383 [00:39<00:26,  5.77it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▊                               | 230/383 [00:39<00:26,  5.79it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████                               | 231/383 [00:39<00:26,  5.81it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▏                              | 232/383 [00:39<00:25,  5.83it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▍                              | 233/383 [00:39<00:25,  5.85it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▋                              | 234/383 [00:39<00:25,  5.86it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▊                              | 235/383 [00:39<00:25,  5.88it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████                              | 236/383 [00:40<00:24,  5.90it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▎                             | 237/383 [00:40<00:24,  5.92it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▍                             | 238/383 [00:40<00:24,  5.93it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▋                             | 239/383 [00:40<00:24,  5.95it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▉                             | 240/383 [00:40<00:23,  5.97it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████                             | 241/383 [00:40<00:23,  5.98it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▎                            | 242/383 [00:40<00:23,  6.00it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▍                            | 243/383 [00:40<00:23,  6.02it/s, loss=5.54, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  64%|█████████████████████████████████████████████████▋                            | 244/383 [00:40<00:23,  6.04it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▉                            | 245/383 [00:40<00:22,  6.05it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████                            | 246/383 [00:40<00:22,  6.07it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████▎                           | 247/383 [00:40<00:22,  6.09it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▌                           | 248/383 [00:40<00:22,  6.10it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▋                           | 249/383 [00:40<00:21,  6.12it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▉                           | 250/383 [00:40<00:21,  6.14it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████                           | 251/383 [00:40<00:21,  6.16it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▎                          | 252/383 [00:40<00:21,  6.17it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 253/383 [00:40<00:21,  6.19it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▋                          | 254/383 [00:40<00:20,  6.21it/s, loss=5.54, v_num=]\u001b[A\n",
      "Epoch 0:  67%|███████████████████████████████████████████████████▉                          | 255/383 [00:40<00:20,  6.23it/s, loss=5.54, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_accuracy' reached 0.01600 (best 0.01600), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211450/epoch=0-step=8-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  67%|███████████████████████████████████████████████████▉                          | 255/383 [01:02<00:31,  4.11it/s, loss=5.54, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.76it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.66it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211450 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 581/581 [01:38<00:00,  5.92it/s]\n",
      "predicting class labels for test split\n",
      "Predicting DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████| 316/316 [00:55<00:00,  5.74it/s]\n",
      "test round:  5 accuracy:  0.009504009504009503\n",
      "computing active learning scores\n",
      "getting idx to relabel\n",
      "setting up next iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:335: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  pred_probs = pred_probs / np.sum(pred_probs, axis=1)[:, np.newaxis]\n",
      "/home/ubuntu/cleanlab/cleanlab/internal/multiannotator_utils.py:341: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  scaled_pred_probs / np.sum(scaled_pred_probs, axis=1)[:, np.newaxis]\n",
      "Global seed set to 123\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230324_211912/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                            | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | model             | TimmAutoModelForImagePrediction | 87.0 M\n",
      "1 | validation_metric | Accuracy                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss                | 0     \n",
      "----------------------------------------------------------------------\n",
      "87.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.0 M    Total params\n",
      "174.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  34%|██████████████████████████▌                                                   | 135/396 [00:18<00:36,  7.16it/s, loss=5.53, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  34%|██████████████████████████▊                                                   | 136/396 [00:19<00:36,  7.06it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  35%|██████████████████████████▉                                                   | 137/396 [00:19<00:36,  7.09it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▏                                                  | 138/396 [00:19<00:36,  7.13it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▍                                                  | 139/396 [00:19<00:35,  7.16it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  35%|███████████████████████████▌                                                  | 140/396 [00:19<00:35,  7.19it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▊                                                  | 141/396 [00:19<00:35,  7.22it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  36%|███████████████████████████▉                                                  | 142/396 [00:19<00:35,  7.25it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▏                                                 | 143/396 [00:19<00:34,  7.29it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  36%|████████████████████████████▎                                                 | 144/396 [00:19<00:34,  7.32it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▌                                                 | 145/396 [00:19<00:34,  7.35it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▊                                                 | 146/396 [00:19<00:33,  7.38it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  37%|████████████████████████████▉                                                 | 147/396 [00:19<00:33,  7.41it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  37%|█████████████████████████████▏                                                | 148/396 [00:19<00:33,  7.44it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▎                                                | 149/396 [00:19<00:33,  7.47it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▌                                                | 150/396 [00:19<00:32,  7.50it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▋                                                | 151/396 [00:20<00:32,  7.53it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  38%|█████████████████████████████▉                                                | 152/396 [00:20<00:32,  7.56it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▏                                               | 153/396 [00:20<00:32,  7.59it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▎                                               | 154/396 [00:20<00:31,  7.62it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▌                                               | 155/396 [00:20<00:31,  7.65it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  39%|██████████████████████████████▋                                               | 156/396 [00:20<00:31,  7.68it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  40%|██████████████████████████████▉                                               | 157/396 [00:20<00:31,  7.71it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████                                               | 158/396 [00:20<00:30,  7.74it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▎                                              | 159/396 [00:20<00:30,  7.76it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  40%|███████████████████████████████▌                                              | 160/396 [00:20<00:30,  7.79it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▋                                              | 161/396 [00:20<00:30,  7.82it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  41%|███████████████████████████████▉                                              | 162/396 [00:20<00:29,  7.85it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████                                              | 163/396 [00:20<00:29,  7.88it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  41%|████████████████████████████████▎                                             | 164/396 [00:20<00:29,  7.91it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▌                                             | 165/396 [00:20<00:29,  7.93it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▋                                             | 166/396 [00:20<00:28,  7.96it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  42%|████████████████████████████████▉                                             | 167/396 [00:20<00:28,  7.99it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  42%|█████████████████████████████████                                             | 168/396 [00:20<00:28,  8.02it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▎                                            | 169/396 [00:21<00:28,  8.04it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▍                                            | 170/396 [00:21<00:28,  8.07it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▋                                            | 171/396 [00:21<00:27,  8.10it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  43%|█████████████████████████████████▉                                            | 172/396 [00:21<00:27,  8.12it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████                                            | 173/396 [00:21<00:27,  8.15it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▎                                           | 174/396 [00:21<00:27,  8.18it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▍                                           | 175/396 [00:21<00:26,  8.20it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  44%|██████████████████████████████████▋                                           | 176/396 [00:21<00:26,  8.23it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  45%|██████████████████████████████████▊                                           | 177/396 [00:21<00:26,  8.26it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████                                           | 178/396 [00:21<00:26,  8.28it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▎                                          | 179/396 [00:21<00:26,  8.31it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  45%|███████████████████████████████████▍                                          | 180/396 [00:21<00:25,  8.34it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▋                                          | 181/396 [00:21<00:25,  8.36it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  46%|███████████████████████████████████▊                                          | 182/396 [00:21<00:25,  8.39it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████                                          | 183/396 [00:21<00:25,  8.41it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  46%|████████████████████████████████████▏                                         | 184/396 [00:21<00:25,  8.44it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▍                                         | 185/396 [00:21<00:24,  8.46it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  47%|████████████████████████████████████▋                                         | 186/396 [00:21<00:24,  8.49it/s, loss=5.53, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  47%|████████████████████████████████████▊                                         | 187/396 [00:21<00:24,  8.51it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  47%|█████████████████████████████████████                                         | 188/396 [00:22<00:24,  8.54it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▏                                        | 189/396 [00:22<00:24,  8.56it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▍                                        | 190/396 [00:22<00:23,  8.59it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▌                                        | 191/396 [00:22<00:23,  8.61it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  48%|█████████████████████████████████████▊                                        | 192/396 [00:22<00:23,  8.64it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████                                        | 193/396 [00:22<00:23,  8.66it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▏                                       | 194/396 [00:22<00:23,  8.69it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▍                                       | 195/396 [00:22<00:23,  8.71it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  49%|██████████████████████████████████████▌                                       | 196/396 [00:22<00:22,  8.73it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  50%|██████████████████████████████████████▊                                       | 197/396 [00:22<00:22,  8.76it/s, loss=5.53, v_num=]\u001b[A\n",
      "Epoch 0:  50%|███████████████████████████████████████                                       | 198/396 [00:22<00:22,  8.79it/s, loss=5.53, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_accuracy' reached 0.01000 (best 0.01000), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211912/epoch=0-step=8.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:00:40. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████████████████████████████▏                                      | 199/396 [00:40<00:39,  4.97it/s, loss=5.52, v_num=]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                                         | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                                            | 0/63 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▍                                      | 200/396 [00:40<00:39,  4.95it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▌                                      | 201/396 [00:40<00:39,  4.96it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▊                                      | 202/396 [00:40<00:38,  4.98it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  51%|███████████████████████████████████████▉                                      | 203/396 [00:40<00:38,  5.00it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▏                                     | 204/396 [00:40<00:38,  5.02it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▍                                     | 205/396 [00:40<00:37,  5.03it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▌                                     | 206/396 [00:40<00:37,  5.05it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  52%|████████████████████████████████████████▊                                     | 207/396 [00:40<00:37,  5.07it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  53%|████████████████████████████████████████▉                                     | 208/396 [00:40<00:36,  5.09it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▏                                    | 209/396 [00:40<00:36,  5.11it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▎                                    | 210/396 [00:40<00:36,  5.12it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  53%|█████████████████████████████████████████▌                                    | 211/396 [00:41<00:35,  5.14it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▊                                    | 212/396 [00:41<00:35,  5.16it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  54%|█████████████████████████████████████████▉                                    | 213/396 [00:41<00:35,  5.18it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▏                                   | 214/396 [00:41<00:35,  5.19it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  54%|██████████████████████████████████████████▎                                   | 215/396 [00:41<00:34,  5.21it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▌                                   | 216/396 [00:41<00:34,  5.23it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▋                                   | 217/396 [00:41<00:34,  5.25it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  55%|██████████████████████████████████████████▉                                   | 218/396 [00:41<00:33,  5.26it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  55%|███████████████████████████████████████████▏                                  | 219/396 [00:41<00:33,  5.28it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▎                                  | 220/396 [00:41<00:33,  5.30it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▌                                  | 221/396 [00:41<00:32,  5.32it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▋                                  | 222/396 [00:41<00:32,  5.33it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  56%|███████████████████████████████████████████▉                                  | 223/396 [00:41<00:32,  5.35it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████                                  | 224/396 [00:41<00:32,  5.37it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▎                                 | 225/396 [00:41<00:31,  5.39it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▌                                 | 226/396 [00:41<00:31,  5.40it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  57%|████████████████████████████████████████████▋                                 | 227/396 [00:41<00:31,  5.42it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  58%|████████████████████████████████████████████▉                                 | 228/396 [00:41<00:30,  5.44it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████                                 | 229/396 [00:41<00:30,  5.45it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▎                                | 230/396 [00:42<00:30,  5.47it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  58%|█████████████████████████████████████████████▌                                | 231/396 [00:42<00:30,  5.49it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▋                                | 232/396 [00:42<00:29,  5.50it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  59%|█████████████████████████████████████████████▉                                | 233/396 [00:42<00:29,  5.52it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████                                | 234/396 [00:42<00:29,  5.54it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  59%|██████████████████████████████████████████████▎                               | 235/396 [00:42<00:28,  5.55it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▍                               | 236/396 [00:42<00:28,  5.57it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▋                               | 237/396 [00:42<00:28,  5.59it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  60%|██████████████████████████████████████████████▉                               | 238/396 [00:42<00:28,  5.60it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  60%|███████████████████████████████████████████████                               | 239/396 [00:42<00:27,  5.62it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▎                              | 240/396 [00:42<00:27,  5.64it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▍                              | 241/396 [00:42<00:27,  5.65it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▋                              | 242/396 [00:42<00:27,  5.67it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  61%|███████████████████████████████████████████████▊                              | 243/396 [00:42<00:26,  5.69it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████                              | 244/396 [00:42<00:26,  5.70it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▎                             | 245/396 [00:42<00:26,  5.72it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▍                             | 246/396 [00:42<00:26,  5.74it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  62%|████████████████████████████████████████████████▋                             | 247/396 [00:42<00:25,  5.75it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  63%|████████████████████████████████████████████████▊                             | 248/396 [00:42<00:25,  5.77it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████                             | 249/396 [00:43<00:25,  5.78it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  63%|█████████████████████████████████████████████████▏                            | 250/396 [00:43<00:25,  5.80it/s, loss=5.52, v_num=]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  63%|█████████████████████████████████████████████████▍                            | 251/396 [00:43<00:24,  5.82it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▋                            | 252/396 [00:43<00:24,  5.83it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  64%|█████████████████████████████████████████████████▊                            | 253/396 [00:43<00:24,  5.85it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████                            | 254/396 [00:43<00:24,  5.86it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  64%|██████████████████████████████████████████████████▏                           | 255/396 [00:43<00:23,  5.88it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▍                           | 256/396 [00:43<00:23,  5.90it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▌                           | 257/396 [00:43<00:23,  5.91it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  65%|██████████████████████████████████████████████████▊                           | 258/396 [00:43<00:23,  5.93it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  65%|███████████████████████████████████████████████████                           | 259/396 [00:43<00:23,  5.94it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▏                          | 260/396 [00:43<00:22,  5.96it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▍                          | 261/396 [00:43<00:22,  5.98it/s, loss=5.52, v_num=]\u001b[A\n",
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 262/396 [00:43<00:22,  5.99it/s, loss=5.52, v_num=]\u001b[A\n",
      "                                                                                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 8: 'val_accuracy' reached 0.01000 (best 0.01000), saving model to '/home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211912/epoch=0-step=8-v1.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  66%|███████████████████████████████████████████████████▌                          | 262/396 [01:04<00:32,  4.07it/s, loss=5.52, v_num=]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.49it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.47it/s]\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:automm:Models and intermediate outputs are saved to /home/ubuntu/examples/active_learning_single_annotator/AutogluonModels/ag-20230324_211912 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtaining predicted class probabilities for the unlabeled data\n",
      "Predicting DataLoader 0:  46%|████████████████████████████████████▊                                            | 263/578 [00:46<00:55,  5.71it/s]"
     ]
    }
   ],
   "source": [
    "model_accuracy_arr = np.full(num_rounds, np.nan)\n",
    "\n",
    "for i in range(num_rounds):\n",
    "    # train model and obtain predicted class probabilities for the unlabeled data\n",
    "    print('fitting model')\n",
    "    predictor = train(df_labeled, out_folder=None, time_limit=30)\n",
    "    \n",
    "    print('obtaining predicted class probabilities for the unlabeled data')\n",
    "    pred_probs_unlabeled = predictor.predict_proba(df_unlabeled)\n",
    "        \n",
    "    print('computing active learning scores')\n",
    "    # compute active learning scores\n",
    "    _, active_learning_scores_unlabeled = get_active_learning_scores(\n",
    "        df_labeled['label'].to_numpy(), pred_probs_unlabeled=pred_probs_unlabeled\n",
    "    )\n",
    "    \n",
    "    print('getting idx to relabel')\n",
    "    # get the indices of examples to collect more labels for\n",
    "    relabel_idx_unlabeled = get_idx_to_label(\n",
    "        active_learning_scores_unlabeled=active_learning_scores_unlabeled,\n",
    "        batch_size_to_label=batch_size_to_label,\n",
    "    )\n",
    "    \n",
    "    print('setting up next iter')\n",
    "    # format the data for the next round of active learning, ie. moving some unlabeled \n",
    "    # examples to the labeled pool because we are collecting labels for them\n",
    "    df_labeled, df_unlabeled = setup_next_iter_data(df_labeled, df_unlabeled, relabel_idx_unlabeled)\n",
    "    \n",
    "    # evaluate model accuracy for the current round on held-out test data. This is an optional step \n",
    "    # for demonstration purposes, in practical applications you may not have ground truth labels\n",
    "    print('predicting class labels for test split')\n",
    "    pred_labels = predictor.predict(data=df_test)\n",
    "    true_labels_test = np.array(df_test['label'].tolist())\n",
    "    model_accuracy_arr[i] = np.mean(pred_labels == true_labels_test)\n",
    "    print('test round: ', i, 'accuracy: ', np.mean(pred_labels == true_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Below, we can see that the model accuracy increases steadily with each additional round of data labeling and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initial model test accuracy: {model_accuracy_arr[0]:.3}\")\n",
    "print(f\"Final model test accuracy (after 15 rounds of active learning): {model_accuracy_arr[-1]:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"model_acc_20_rounds_activelab\", model_accuracy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_accuracy_arr)\n",
    "plt.xticks(range(num_rounds))\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Griffin, G., Holub, A., & Perona, P. (2022). Caltech 256 (1.0). https://doi.org/10.22002/D1.20087\n",
    "\n",
    "Goh, H. W., & Mueller, J. ActiveLab: Active Learning with Re-Labeling by Multiple Annotators. https://arxiv.org/abs/2301.11856"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "00885e89789f58e60dbba52a405dc834aaf92411914fde0d391f9b48289a0610"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
