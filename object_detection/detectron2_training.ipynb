{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Object Detection model using Detectron2\n",
    "\n",
    "This notebook demonstrates how to train a [Detectron2](https://github.com/facebookresearch/detectron2/) model on object detection datasets and produce predictions required to run cleanlab's tutorial on detecting label errors in object detectionÂ data.  Note that this notebook fits the model to an entire training set and produces predictions on a held-out validation set. Thus these predictions are only *out-of-sample* for the validation data, and should ideally *only* be used to find mislabeled images amongst the validation set. To instead find mislabeled images amongst an entire dataset, see the analogous notebook in this folder which uses K-fold cross-validation to produce out-of-sample predictions for every image in the dataset.\n",
    "\n",
    "In object detection data, each image is annotated with multiple bounding boxes.  Each bounding box surrounds a physical object within an image scene, and is annotated with a given class label. Using this labeled data, we train a model to predict the locations and classes of objects in an image. The trained model can subsequently be used to identify mislabeled images, which when corrected, allow you to train an even better model without changing your training code! \n",
    "\n",
    "Here we will fit a state-of-the-art neural network trained starting from a pretrained [X-101](https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md#imagenet-pretrained-models) network backbone. First let's import the required packages and download the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/examples/blob/master/object_detection/detectron2_training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import pickle\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/instances_val2017_5labels.json\"\n",
    "!wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/instances_train2017_5labels.json\"\n",
    "!wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/tutorial_obj/labels.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin training on a custom dataset, be sure to review the COCO dataset guidelines for formatting your data, which can be found on their [website](https://cocodataset.org/#format-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a custom dataset named \"my_dataset\" for training. A subset of the labels [\"car\", \"chair\", \"cup\", \"person\", and \"traffic light\"] are used for training and detecting errors in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"../data/coco/\"\n",
    "TRAIN_PATH = os.path.join(IMAGE_PATH,\"train2017\")\n",
    "VAL_PATH = os.path.join(IMAGE_PATH,\"val2017\")\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"instances_train2017_5labels.json\",\n",
    "                        TRAIN_PATH)\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"instances_val2017_5labels.json\",\n",
    "                        VAL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the configuration settings for training an object detection model using Detectron2. The model architecture used in this example is \"faster_rcnn_X_101_32x8d_FPN_3x\" from the COCO-Detection model zoo. The training data is specified by the \"my_dataset_train\" dataset and validation data is specified by the \"my_dataset_val\" dataset which refer to COCO2017 train and val containing only the subset of labels specified before.\n",
    "\n",
    "Here the number of worker threads is set to 2 and the batch size is set to 2. The learning rate and maximum number of iterations are also specified. You'll want to tinker with these values to get the best performance for your own data.\n",
    "The model is initialized from the COCO-Detection model zoo and the output directory for the trained model is created. Finally, this configuration is passed to the DefaultTrainer class for training the object detection model.\n",
    "\n",
    "<strong>Note:</strong> The number of iterations was set based on [early stopping.](https://en.wikipedia.org/wiki/Early_stopping#:~:text=In%20machine%20learning%2C%20early%20stopping,training%20data%20with%20each%20iteration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # IMPORTANT: pick a good Learning Rate for your dataset \n",
    "cfg.SOLVER.MAX_ITER = 30000    # \n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # only 5 classes [\"car\", \"chair\", \"cup\", \"person\", and \"traffic light\"] \n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference & evaluation using the trained model\n",
    "If you wish to load a trained model to run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"../output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below defines a function \"format_detectron2_predictions\" to convert the prediction output of Detectron2 to a format that can be used by Cleanlab for identifying label errors. This function accepts the predicted object instances and the number of classes as inputs. It processes the predicted bounding boxes and prediction-confidence for each instance, and outputs a list of numpy arrays containing the bounding boxes and prediction-confidence for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_detectron2_predictions(ins,num_classes):\n",
    "    fields = ins.get_fields()\n",
    "    boxes = fields['pred_boxes'].tensor.numpy()\n",
    "    res = [[] for i in range(num_classes)]\n",
    "    for i in range(0,len(fields['pred_classes'])):\n",
    "        pred_class = fields['pred_classes'][i].item()\n",
    "        probs = ins.get_fields()['scores'][i].item()\n",
    "        box_cord = list(boxes[i])\n",
    "        box_cord.append(probs)\n",
    "        res[pred_class].append(box_cord)\n",
    "    res2 = []\n",
    "    for i in res:\n",
    "        if len(i)==0:\n",
    "            q = np.array(i,dtype=np.float32).reshape((0,num_classes))\n",
    "        else:\n",
    "            q = np.array(i,dtype=np.float32)\n",
    "        res2.append(q)\n",
    "    return res2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform inference and testing on the tutorial notebook linked here, we utilize a limited portion of the validation set of COCO 2017. To find label errors in this subset, please run our [tutorial](https://docs.cleanlab.ai/stable/index.html) notebook on [Finding Label Errors in Object Detection Datasets](https://github.com/cleanlab/cleanlab/blob/master/docs/source/tutorials/object_detection.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pickle.load(open(\"labels.pkl\",'rb'))\n",
    "results = []\n",
    "for i in labels:\n",
    "    im_name = os.path.join(VAL_PATH, i['seg_map'].replace(\".png\",'.jpg'))\n",
    "    im = cv2.imread(im_name)\n",
    "    outputs = predictor(im)\n",
    "    results.append(format_detectron2_predictions(outputs[\"instances\"].to(\"cpu\"),cfg.MODEL.ROI_HEADS.NUM_CLASSES))\n",
    "    \n",
    "pickle.dump(results,open(\"predictions.pkl\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
