{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Object Detection model using Detectron2\n",
    "\n",
    "This 5-minute quickstart tutorial demonstrates how to train Detectron2 on object detection datasets. In this dataset each example contains a bounding box and a class label surrounding a physical object within an image scene. Using this labeled data, we train a model to predict classes of objects in an image and their physical locations.\n",
    "\n",
    "This notebook demonstrates how to train a state-of-the-art object detection model using Detectron2 andÂ use it to produce `pred_probs`, which will help detect label errors in Object detection datasets. \n",
    "\n",
    "To identify label errors, we provide an [example](https://github.com/cleanlab/examples/) notebook on our GitHub repository on [Finding Label Errors in Object Detection Datasets](https://github.com/cleanlab/cleanlab/blob/master/docs/source/tutorials/object_detection.ipynb). Here we fit a state-of-the-art neural network initialized from a pretrained [X-101](https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md#imagenet-pretrained-models) network backbone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cleanlab/examples/blob/master/object_detection/detectron2_training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import pickle\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/test_coco_0_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/test_coco_1_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/test_coco_2_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/test_coco_3_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/test_coco_4_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/train_coco_0_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/train_coco_1_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/train_coco_2_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/train_coco_3_fold.json\"\n",
    "# !wget -nc \"https://cleanlab-public.s3.amazonaws.com/ObjectDetectionBenchmarking/DATASET_annotations/train_coco_4_fold.json\"\n",
    "# !wget -nc \"http://images.cocodataset.org/zips/val2017.zip\" && unzip -q -o val2017.zip\n",
    "# !wget -nc \"http://images.cocodataset.org/zips/train2017.zip\" && unzip -q -o train2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the [COCOdataset](https://cocodataset.org/#download)\n",
    "\n",
    "Before you begin training on a custom dataset, be sure to review the COCO dataset guidelines for formatting your data, which can be found on their [website](https://cocodataset.org/#format-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a custom dataset named \"my_dataset\" with detectron2, users must implement a function that returns the items in the dataset and then inform detectron2 about this function. For instance, a subset of the labels [\"car\", \"chair\", \"cup\", \"person\", and \"traffic light\"] are used for training and detecting errors in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"\"\n",
    "TRAIN_PATH = os.path.join(IMAGE_PATH,\"train2017\")\n",
    "VAL_PATH = os.path.join(IMAGE_PATH,\"val2017\")\n",
    "pairs = []\n",
    "for k in range(0,5):\n",
    "    train_name = f\"train_coco_{k}_fold\"\n",
    "    json_train = train_name+\".json\"\n",
    "    test_name = f\"test_coco_{k}_fold\"\n",
    "    json_test= train_name+\".json\"\n",
    "    register_coco_instances(train_name, {}, json_train,\n",
    "                        TRAIN_PATH)\n",
    "    register_coco_instances(test_name, {}, json_test,\n",
    "                        VAL_PATH)\n",
    "    pairs.append((train_name,test_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the configuration settings for training an object detection model using Detectron2. The model architecture used in this example is \"faster_rcnn_X_101_32x8d_FPN_3x\" from the COCO-Detection model zoo. The training data is specified by the \"my_dataset_train\" dataset and validation data is specified by the \"my_dataset_val\" dataset which refer to COCO2017 train and val containing only the subset of labels specified before.\n",
    "\n",
    "The number of worker threads is set to 2 and the batch size is set to 2.\n",
    "The learning rate and maximum number of iterations are also specified. The model is initialized from the COCO-Detection model zoo and the output directory for the trained model is created. Finally, the configuration is passed to the DefaultTrainer class for training the object detection model.\n",
    "\n",
    "<strong>Note:</strong> The number of iterations was set based on [early stopping.](https://en.wikipedia.org/wiki/Early_stopping#:~:text=In%20machine%20learning%2C%20early%20stopping,training%20data%20with%20each%20iteration.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_data(TRAIN,VALIDATION,folder):\n",
    "    cfg = get_cfg()\n",
    "    MODEL = 'faster_rcnn_X_101_32x8d_FPN_3x.yaml'\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\"+MODEL))\n",
    "    cfg.DATASETS.TRAIN = (TRAIN,)\n",
    "    cfg.DATASETS.TEST = (VALIDATION,)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/\"+MODEL)  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = 6000    # \n",
    "    cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". \n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80  # only 5 classes [\"car\", \"chair\", \"cup\", \"person\", and \"traffic light\"] \n",
    "    cfg.OUTPUT_DIR = folder\n",
    "    cfg.TEST.EVAL_PERIOD = 500\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given code block implements a function \"format_detectron2_predictions\" that converts the output of Detectron2 to a format that can be used by Cleanlab for identifying label errors. The function accepts the predicted instances and the number of classes as inputs. It processes the predicted bounding boxes and scores for each instance, and outputs a list of numpy arrays containing the bounding boxes and scores for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_detectron2_predictions(ins,num_classes):\n",
    "    fields = ins.get_fields()\n",
    "    boxes = fields['pred_boxes'].tensor.numpy()\n",
    "    res = [[] for i in range(num_classes)]\n",
    "    for i in range(0,len(fields['pred_classes'])):\n",
    "        pred_class = fields['pred_classes'][i].item()\n",
    "        probs = ins.get_fields()['scores'][i].item()\n",
    "        box_cord = list(boxes[i])\n",
    "        box_cord.append(probs)\n",
    "        res[pred_class].append(box_cord)\n",
    "    res2 = []\n",
    "    for i in res:\n",
    "        if len(i)==0:\n",
    "            q = np.array(i,dtype=np.float32).reshape((0,num_classes))\n",
    "        else:\n",
    "            q = np.array(i,dtype=np.float32)\n",
    "        res2.append(q)\n",
    "    return res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = json.load(open(\"../\"+pairs[k][1]+'.json','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for k in range(0,len(pairs)):\n",
    "    train_data = pairs[k][0]\n",
    "    val_data = pairs[k][1]\n",
    "    train_data(train_data,val_data,\"COCO_TRAIN_\"+str(k)+\"_FOLD\")\n",
    "    evaluator = COCOEvaluator(val_data, output_dir=\"output\")\n",
    "    val_loader = build_detection_test_loader(cfg, val_data)\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    dataset = json.load(open(\"../\"+pairs[k][1]+'.json','rb'))\n",
    "    for image in dat['images']:\n",
    "        im_name = os.path.join(TRAIN_PATH, i['file_name'])\n",
    "        im = cv2.imread(im_name)\n",
    "        outputs = predictor(im)\n",
    "        result_dict[im_name](format_detectron2_predictions(outputs[\"instances\"].to(\"cpu\"),cfg.MODEL.ROI_HEADS.NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"TRAIN_COCO_ALL_labels.pkl\",'rb'))\n",
    "results = []\n",
    "for i in dataset:\n",
    "    im_name = os.path.join(TRAIN_PATH, i['seg_map'].replace(\".png\",'.jpg'))\n",
    "    results.append(result_dict[im_name])\n",
    "    \n",
    "pickle.dump(results,open(\"results_train_ALL.pkl\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
