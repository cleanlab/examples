{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8b9b58",
   "metadata": {
    "papermill": {
     "duration": 0.005642,
     "end_time": "2022-04-06T01:00:08.761345",
     "exception": false,
     "start_time": "2022-04-06T01:00:08.755703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameter Optimization Tutorial\n",
    "\n",
    "This tutorial will show you the main hyper-parameters for LearningWithNoisyLabels. There are only two!\n",
    "\n",
    "1. `filter_by` : str (default: `'prune_by_noise_rate'`), Method used for pruning.\n",
    "    * Values: [`'prune_by_class'`, `'prune_by_noise_rate'`, or `'both'`]. \n",
    "    * `'prune_by_noise_rate'`: works by removing examples with *high probability* of being mislabeled for every non-diagonal in the prune_counts_matrix (see filter.py).\n",
    "    * `'prune_by_class'`: works by removing the examples with *smallest probability* of belonging to their given class label for every class.\n",
    "    * `'both'`: Finds the examples satisfying (1) AND (2) and removes their set conjunction. \n",
    "\n",
    "\n",
    "2. converge_latent_estimates : bool (Default: False)\n",
    "    * If true, forces numerical consistency of latent estimates. Each is estimated independently, but they are related mathematically with closed form  equivalences. This will iteratively enforce mathematically consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c843175c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T01:00:08.773717Z",
     "iopub.status.busy": "2022-04-06T01:00:08.773144Z",
     "iopub.status.idle": "2022-04-06T01:00:08.784962Z",
     "shell.execute_reply": "2022-04-06T01:00:08.784220Z"
    },
    "papermill": {
     "duration": 0.021238,
     "end_time": "2022-04-06T01:00:08.787904",
     "exception": false,
     "start_time": "2022-04-06T01:00:08.766666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python 2 and 3 compatibility\n",
    "from __future__ import (\n",
    "    print_function,\n",
    "    absolute_import,\n",
    "    division,\n",
    "    unicode_literals,\n",
    "    with_statement,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89454c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T01:00:08.796279Z",
     "iopub.status.busy": "2022-04-06T01:00:08.796001Z",
     "iopub.status.idle": "2022-04-06T01:00:10.166380Z",
     "shell.execute_reply": "2022-04-06T01:00:10.165655Z"
    },
    "papermill": {
     "duration": 1.377148,
     "end_time": "2022-04-06T01:00:10.169172",
     "exception": false,
     "start_time": "2022-04-06T01:00:08.792024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cleanlab.classification import LearningWithNoisyLabels\n",
    "from cleanlab.noise_generation import generate_noise_matrix_from_trace\n",
    "from cleanlab.noise_generation import generate_noisy_labels\n",
    "from cleanlab.internal.util import print_noise_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96441cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T01:00:10.177988Z",
     "iopub.status.busy": "2022-04-06T01:00:10.177562Z",
     "iopub.status.idle": "2022-04-06T01:00:10.184785Z",
     "shell.execute_reply": "2022-04-06T01:00:10.184124Z"
    },
    "papermill": {
     "duration": 0.013387,
     "end_time": "2022-04-06T01:00:10.186570",
     "exception": false,
     "start_time": "2022-04-06T01:00:10.173183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_linear_dataset(n_classes=3, n_samples=300):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=2,\n",
    "        n_redundant=0,\n",
    "        n_informative=2,\n",
    "        random_state=1,\n",
    "        n_clusters_per_class=1,\n",
    "        n_classes=n_classes,\n",
    "    )\n",
    "    rng = np.random.RandomState(2)\n",
    "    X += 2 * rng.uniform(size=X.shape)\n",
    "    return (X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d700da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T01:00:10.194059Z",
     "iopub.status.busy": "2022-04-06T01:00:10.193774Z",
     "iopub.status.idle": "2022-04-06T01:00:10.198170Z",
     "shell.execute_reply": "2022-04-06T01:00:10.197363Z"
    },
    "papermill": {
     "duration": 0.010139,
     "end_time": "2022-04-06T01:00:10.199978",
     "exception": false,
     "start_time": "2022-04-06T01:00:10.189839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "param_grid = {\n",
    "    \"find_label_issues_kwargs\": [\n",
    "        {\"filter_by\": \"prune_by_noise_rate\"},\n",
    "        {\"filter_by\": \"prune_by_class\"},\n",
    "        {\"filter_by\": \"both\"},\n",
    "    ],\n",
    "    \"converge_latent_estimates\": [True, False],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21da0eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T01:00:10.206183Z",
     "iopub.status.busy": "2022-04-06T01:00:10.205860Z",
     "iopub.status.idle": "2022-04-06T01:00:10.214878Z",
     "shell.execute_reply": "2022-04-06T01:00:10.214233Z"
    },
    "papermill": {
     "duration": 0.014726,
     "end_time": "2022-04-06T01:00:10.217239",
     "exception": false,
     "start_time": "2022-04-06T01:00:10.202513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the sparsity of the noise matrix.\n",
    "frac_zero_noise_rates = 0.0  # Consider increasing to 0.5\n",
    "# A proxy for the fraction of labels that are correct.\n",
    "avg_trace = 0.65  # ~35% wrong labels. Increasing makes the problem easier.\n",
    "# Amount of data for each dataset.\n",
    "dataset_size = 250  # Try 250 or 400 to use less or more data.\n",
    "num_classes = 3\n",
    "\n",
    "ds = make_linear_dataset(n_classes=num_classes, n_samples=num_classes * dataset_size)\n",
    "X, y = ds\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3518f1-196a-45de-af76-0bfe9b91437b",
   "metadata": {
    "papermill": {
     "duration": 0.00327,
     "end_time": "2022-04-06T01:00:10.224305",
     "exception": false,
     "start_time": "2022-04-06T01:00:10.221035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run hyper-parameter search with sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6a1a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-06T01:00:10.230000Z",
     "iopub.status.busy": "2022-04-06T01:00:10.229720Z",
     "iopub.status.idle": "2022-04-06T01:00:19.429736Z",
     "shell.execute_reply": "2022-04-06T01:00:19.428858Z"
    },
    "papermill": {
     "duration": 9.2063,
     "end_time": "2022-04-06T01:00:19.432808",
     "exception": false,
     "start_time": "2022-04-06T01:00:10.226508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " =========== \n",
      " Naive Bayes \n",
      " ===========\n",
      "\n",
      " Noise Matrix (aka Noisy Channel) P(labels|y) of shape (3, 3)\n",
      " p(labe\ty=0\ty=1\ty=2\n",
      "\t---\t---\t---\n",
      "labels=0 |\t0.52\t0.1\t0.34\n",
      "labels=1 |\t0.2\t0.82\t0.05\n",
      "labels=2 |\t0.28\t0.07\t0.61\n",
      "\tTrace(matrix) = 1.95\n",
      "\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 133 datapoints with label issues ...\n",
      "Remaining clean data has 227 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 146 datapoints with label issues ...\n",
      "Remaining clean data has 214 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 143 datapoints with label issues ...\n",
      "Remaining clean data has 217 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 142 datapoints with label issues ...\n",
      "Remaining clean data has 218 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 140 datapoints with label issues ...\n",
      "Remaining clean data has 220 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 170 datapoints with label issues ...\n",
      "Remaining clean data has 190 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 161 datapoints with label issues ...\n",
      "Remaining clean data has 199 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 156 datapoints with label issues ...\n",
      "Remaining clean data has 204 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 162 datapoints with label issues ...\n",
      "Remaining clean data has 198 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 159 datapoints with label issues ...\n",
      "Remaining clean data has 201 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 133 datapoints with label issues ...\n",
      "Remaining clean data has 227 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 142 datapoints with label issues ...\n",
      "Remaining clean data has 218 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 135 datapoints with label issues ...\n",
      "Remaining clean data has 225 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 139 datapoints with label issues ...\n",
      "Remaining clean data has 221 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 129 datapoints with label issues ...\n",
      "Remaining clean data has 231 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 137 datapoints with label issues ...\n",
      "Remaining clean data has 223 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 144 datapoints with label issues ...\n",
      "Remaining clean data has 216 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 140 datapoints with label issues ...\n",
      "Remaining clean data has 220 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 140 datapoints with label issues ...\n",
      "Remaining clean data has 220 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 138 datapoints with label issues ...\n",
      "Remaining clean data has 222 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 165 datapoints with label issues ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining clean data has 195 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 161 datapoints with label issues ...\n",
      "Remaining clean data has 199 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 159 datapoints with label issues ...\n",
      "Remaining clean data has 201 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 162 datapoints with label issues ...\n",
      "Remaining clean data has 198 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 158 datapoints with label issues ...\n",
      "Remaining clean data has 202 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 135 datapoints with label issues ...\n",
      "Remaining clean data has 225 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 133 datapoints with label issues ...\n",
      "Remaining clean data has 227 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 132 datapoints with label issues ...\n",
      "Remaining clean data has 228 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 144 datapoints with label issues ...\n",
      "Remaining clean data has 216 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 128 datapoints with label issues ...\n",
      "Remaining clean data has 232 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 195 datapoints with label issues ...\n",
      "Remaining clean data has 255 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Accuracy with default parameters: 0.65\n",
      "Accuracy with optimized parameters: 0.7\n",
      "\n",
      "Optimal parameter settings using Naive Bayes\n",
      "--------------------------------------------\n",
      "cv : None\n",
      "error_score : nan\n",
      "estimator__clf__priors : None\n",
      "estimator__clf__var_smoothing : 1e-09\n",
      "estimator__clf : GaussianNB()\n",
      "estimator__converge_latent_estimates : False\n",
      "estimator__cv_n_folds : 5\n",
      "estimator__find_label_issues_kwargs : {}\n",
      "estimator__pulearning : None\n",
      "estimator__seed : None\n",
      "estimator__verbose : 1\n",
      "estimator : LearningWithNoisyLabels(clf=GaussianNB())\n",
      "n_jobs : None\n",
      "param_grid : {'find_label_issues_kwargs': [{'filter_by': 'prune_by_noise_rate'}, {'filter_by': 'prune_by_class'}, {'filter_by': 'both'}], 'converge_latent_estimates': [True, False]}\n",
      "pre_dispatch : 2*n_jobs\n",
      "refit : True\n",
      "return_train_score : False\n",
      "scoring : None\n",
      "verbose : 0\n",
      "\n",
      " =================== \n",
      " Logistic Regression \n",
      " ===================\n",
      "\n",
      " Noise Matrix (aka Noisy Channel) P(labels|y) of shape (3, 3)\n",
      " p(labe\ty=0\ty=1\ty=2\n",
      "\t---\t---\t---\n",
      "labels=0 |\t0.52\t0.1\t0.34\n",
      "labels=1 |\t0.2\t0.82\t0.05\n",
      "labels=2 |\t0.28\t0.07\t0.61\n",
      "\tTrace(matrix) = 1.95\n",
      "\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 135 datapoints with label issues ...\n",
      "Remaining clean data has 225 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 137 datapoints with label issues ...\n",
      "Remaining clean data has 223 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 141 datapoints with label issues ...\n",
      "Remaining clean data has 219 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 135 datapoints with label issues ...\n",
      "Remaining clean data has 225 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 137 datapoints with label issues ...\n",
      "Remaining clean data has 223 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 161 datapoints with label issues ...\n",
      "Remaining clean data has 199 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 147 datapoints with label issues ...\n",
      "Remaining clean data has 213 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 155 datapoints with label issues ...\n",
      "Remaining clean data has 205 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 154 datapoints with label issues ...\n",
      "Remaining clean data has 206 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 154 datapoints with label issues ...\n",
      "Remaining clean data has 206 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 128 datapoints with label issues ...\n",
      "Remaining clean data has 232 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 134 datapoints with label issues ...\n",
      "Remaining clean data has 226 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 134 datapoints with label issues ...\n",
      "Remaining clean data has 226 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 128 datapoints with label issues ...\n",
      "Remaining clean data has 232 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 128 datapoints with label issues ...\n",
      "Remaining clean data has 232 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 133 datapoints with label issues ...\n",
      "Remaining clean data has 227 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 139 datapoints with label issues ...\n",
      "Remaining clean data has 221 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 145 datapoints with label issues ...\n",
      "Remaining clean data has 215 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 136 datapoints with label issues ...\n",
      "Remaining clean data has 224 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 136 datapoints with label issues ...\n",
      "Remaining clean data has 224 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 163 datapoints with label issues ...\n",
      "Remaining clean data has 197 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 154 datapoints with label issues ...\n",
      "Remaining clean data has 206 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 162 datapoints with label issues ...\n",
      "Remaining clean data has 198 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 160 datapoints with label issues ...\n",
      "Remaining clean data has 200 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 152 datapoints with label issues ...\n",
      "Remaining clean data has 208 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 124 datapoints with label issues ...\n",
      "Remaining clean data has 236 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 124 datapoints with label issues ...\n",
      "Remaining clean data has 236 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 124 datapoints with label issues ...\n",
      "Remaining clean data has 236 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 128 datapoints with label issues ...\n",
      "Remaining clean data has 232 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 122 datapoints with label issues ...\n",
      "Remaining clean data has 238 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Using predicted probabilities to identify label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 172 datapoints with label issues ...\n",
      "Remaining clean data has 278 datapoints.\n",
      "Assigning sample weights for final training based on estimated label quality ...\n",
      "Fitting final model on the clean data ...\n",
      "Accuracy with default parameters: 0.65\n",
      "Accuracy with optimized parameters: 0.71\n",
      "\n",
      "Optimal parameter settings using Logistic Regression\n",
      "----------------------------------------------------\n",
      "cv : None\n",
      "error_score : nan\n",
      "estimator__clf__C : 1.0\n",
      "estimator__clf__class_weight : None\n",
      "estimator__clf__dual : False\n",
      "estimator__clf__fit_intercept : True\n",
      "estimator__clf__intercept_scaling : 1\n",
      "estimator__clf__l1_ratio : None\n",
      "estimator__clf__max_iter : 100\n",
      "estimator__clf__multi_class : auto\n",
      "estimator__clf__n_jobs : None\n",
      "estimator__clf__penalty : l2\n",
      "estimator__clf__random_state : 0\n",
      "estimator__clf__solver : lbfgs\n",
      "estimator__clf__tol : 0.0001\n",
      "estimator__clf__verbose : 0\n",
      "estimator__clf__warm_start : False\n",
      "estimator__clf : LogisticRegression(random_state=0)\n",
      "estimator__converge_latent_estimates : False\n",
      "estimator__cv_n_folds : 5\n",
      "estimator__find_label_issues_kwargs : {}\n",
      "estimator__pulearning : None\n",
      "estimator__seed : None\n",
      "estimator__verbose : 1\n",
      "estimator : LearningWithNoisyLabels(clf=LogisticRegression(random_state=0))\n",
      "n_jobs : None\n",
      "param_grid : {'find_label_issues_kwargs': [{'filter_by': 'prune_by_noise_rate'}, {'filter_by': 'prune_by_class'}, {'filter_by': 'both'}], 'converge_latent_estimates': [True, False]}\n",
      "pre_dispatch : 2*n_jobs\n",
      "refit : True\n",
      "return_train_score : False\n",
      "scoring : None\n",
      "verbose : 0\n"
     ]
    }
   ],
   "source": [
    "for name, clf in [\n",
    "    (\n",
    "        \"Naive Bayes\",\n",
    "        GaussianNB(),\n",
    "    ),\n",
    "    (\n",
    "        \"Logistic Regression\",\n",
    "        LogisticRegression(random_state=0, solver=\"lbfgs\", multi_class=\"auto\"),\n",
    "    ),\n",
    "]:\n",
    "    print(\"\\n\", \"=\" * len(name), \"\\n\", name, \"\\n\", \"=\" * len(name))\n",
    "    np.random.seed(seed=0)\n",
    "    clf_copy = copy.deepcopy(clf)\n",
    "    # Compute p(y=k), the ground truth class prior on the labels.\n",
    "    py = np.bincount(y_train) / float(len(y_train))\n",
    "    # Generate the noisy channel to characterize the label errors.\n",
    "    noise_matrix = generate_noise_matrix_from_trace(\n",
    "        K=num_classes,\n",
    "        trace=num_classes * avg_trace,\n",
    "        py=py,\n",
    "        frac_zero_noise_rates=frac_zero_noise_rates,\n",
    "    )\n",
    "    print_noise_matrix(noise_matrix)\n",
    "\n",
    "    # Create the noisy labels. This method is exact w.r.t. the noise_matrix.\n",
    "    y_train_with_errors = generate_noisy_labels(y_train, noise_matrix)\n",
    "\n",
    "    # Run GridSearch with Cross-Validation\n",
    "    lnl_cv = GridSearchCV(\n",
    "        estimator=LearningWithNoisyLabels(clf),\n",
    "        param_grid=param_grid,\n",
    "    )\n",
    "    lnl_cv.fit(X=X_train, y=y_train_with_errors)\n",
    "\n",
    "    # Also compute the test score with default parameters\n",
    "    clf_copy.fit(X_train, y_train_with_errors)\n",
    "    score_opt = lnl_cv.score(X_test, y_test)\n",
    "    score_default = clf_copy.score(X_test, y_test)\n",
    "    print(\"Accuracy with default parameters:\", np.round(score_default, 2))\n",
    "    print(\"Accuracy with optimized parameters:\", np.round(score_opt, 2))\n",
    "    print()\n",
    "    s = \"Optimal parameter settings using {}\".format(name)\n",
    "    print(s)\n",
    "    print(\"-\" * len(s))\n",
    "    for key in lnl_cv.get_params().keys():\n",
    "        print(key, \":\", lnl_cv.get_params()[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bcb1b-7742-4d58-be8d-725756a17fea",
   "metadata": {
    "papermill": {
     "duration": 0.007231,
     "end_time": "2022-04-06T01:00:19.449302",
     "exception": false,
     "start_time": "2022-04-06T01:00:19.442071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.959179,
   "end_time": "2022-04-06T01:00:19.776571",
   "environment_variables": {},
   "exception": null,
   "input_path": "model_selection_demo.ipynb",
   "output_path": "model_selection_demo.ipynb",
   "parameters": {},
   "start_time": "2022-04-06T01:00:06.817392",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}